

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Kualitas Air Layak Minum &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Proyek-Sains-Data_Mubessirul-Ummah_Water-Quality/PSD_Water_Quality';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../PSD_Mubessirul%20Ummah_210411100140_Water%20Quality.html"><center><b>PROYEK SAINS DATA WATER QUALITY<b></b></b></center></a></li>







</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FProyek-Sains-Data_Mubessirul-Ummah_Water-Quality/PSD_Water_Quality.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Proyek-Sains-Data_Mubessirul-Ummah_Water-Quality/PSD_Water_Quality.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1><center>Kualitas Air Layak Minum</center></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tujuan">Tujuan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#proses-pengolahan-data">Proses Pengolahan Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#center-data-understanding-center"><center><strong>——Data Understanding——</strong></center></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-data">1. Deskripsi Data</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-fitur-data">2. Deskripsi Fitur Data</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-tipe-data-fitur">3. Deskripsi Tipe Data Fitur</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#identifikasi-missing-value">4. Identifikasi Missing Value</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#identifikasi-duplikasi-data">5. Identifikasi Duplikasi Data</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#explorasi-data-menampilkan-grafik">6. Explorasi Data (Menampilkan Grafik)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#center-pre-processing-center"><center><strong>——Pre Processing——</strong></center></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#menemukan-data-outlier">1. Menemukan Data Outlier</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#balancing-class-data">2. Balancing Class Data</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#seleksi-fitur">3. Seleksi Fitur</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#normalisasi-dan-split-data">4. Normalisasi dan Split Data</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#center-pembuatan-model-center"><center><strong>Pembuatan Model</strong></center></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest">1. Random Forest</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">2. Logistic Regression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#svm">3. SVM</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes">4. Naive Bayes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adaboost">5. Adaboost</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting">6. Gradient Boosting</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-network">7. Neural Network</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#decission-tree">8. Decission Tree</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pycaret">9. Pycaret</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># from google.colab import drive</span>
<span class="c1"># drive.mount(&#39;/content/drive&#39;)</span>
<span class="c1"># %cd /content/drive/MyDrive/folder data</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">IPython</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="c1"># from keras.models import Sequential</span>
<span class="c1"># from keras.layers import Dense</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>

<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">mutual_info_classif</span>
</pre></div>
</div>
</div>
</div>
<p>Nama  : Mubessirul Ummah<br />
NIM   : 210411100140<br />
Kelas : Proyek Sains Data B</p>
<section class="tex2jax_ignore mathjax_ignore" id="center-kualitas-air-layak-minum-center">
<h1><center><strong>Kualitas Air Layak Minum</strong></center><a class="headerlink" href="#center-kualitas-air-layak-minum-center" title="Permalink to this heading">#</a></h1>
<section id="tujuan">
<h2>Tujuan<a class="headerlink" href="#tujuan" title="Permalink to this heading">#</a></h2>
<p>Proses pengolahan data ini akan melakukan klasifikasi serta prediksi terhadap kualitas suatu air layak atau tidak layak dikonsumsi oleh manusia.<br />
klasifikasi pada proses pengolahan data ini akan membedakan air berdasarkan kelas 1 (safe atau aman) dan 0 (not safe atau tidak aman). sedangkan prediksi ini nantinya akan dilakukan melalui model yang telah dibuat pada proses klasifikasi. prediksi ini nantinya akan menggunakan fitur fitur pada data yang telah diseleksi.</p>
</section>
<section id="proses-pengolahan-data">
<h2>Proses Pengolahan Data<a class="headerlink" href="#proses-pengolahan-data" title="Permalink to this heading">#</a></h2>
<section id="center-data-understanding-center">
<h3><center><strong>——Data Understanding——</strong></center><a class="headerlink" href="#center-data-understanding-center" title="Permalink to this heading">#</a></h3>
<center>merupakan sebuah proses untuk mendeskripsikan dan memahami sebuah dataset yang akan kita olah</center><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membaca data dari file excel</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;us-counties.csv&#39;</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">FileNotFoundError</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-3-28fcdb50f39e&gt;</span> in <span class="ni">&lt;cell line: 2&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Membaca data dari file excel</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;us-counties.csv&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">df</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py</span> in <span class="ni">wrapper</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">209</span>                 <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">210</span>                     <span class="n">kwargs</span><span class="p">[</span><span class="n">new_arg_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_arg_value</span>
<span class="ne">--&gt; </span><span class="mi">211</span>             <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">212</span> 
<span class="g g-Whitespace">    </span><span class="mi">213</span>         <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">wrapper</span><span class="p">)</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py</span> in <span class="ni">wrapper</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">329</span>                     <span class="n">stacklevel</span><span class="o">=</span><span class="n">find_stack_level</span><span class="p">(),</span>
<span class="g g-Whitespace">    </span><span class="mi">330</span>                 <span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">331</span>             <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">332</span> 
<span class="g g-Whitespace">    </span><span class="mi">333</span>         <span class="c1"># error: &quot;Callable[[VarArg(Any), KwArg(Any)], Any]&quot; has no</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py</span> in <span class="ni">read_csv</span><span class="nt">(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)</span>
<span class="g g-Whitespace">    </span><span class="mi">948</span>     <span class="n">kwds</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwds_defaults</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">949</span> 
<span class="ne">--&gt; </span><span class="mi">950</span>     <span class="k">return</span> <span class="n">_read</span><span class="p">(</span><span class="n">filepath_or_buffer</span><span class="p">,</span> <span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">951</span> 
<span class="g g-Whitespace">    </span><span class="mi">952</span> 

<span class="nn">/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py</span> in <span class="ni">_read</span><span class="nt">(filepath_or_buffer, kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">603</span> 
<span class="g g-Whitespace">    </span><span class="mi">604</span>     <span class="c1"># Create the parser.</span>
<span class="ne">--&gt; </span><span class="mi">605</span>     <span class="n">parser</span> <span class="o">=</span> <span class="n">TextFileReader</span><span class="p">(</span><span class="n">filepath_or_buffer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">606</span> 
<span class="g g-Whitespace">    </span><span class="mi">607</span>     <span class="k">if</span> <span class="n">chunksize</span> <span class="ow">or</span> <span class="n">iterator</span><span class="p">:</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py</span> in <span class="ni">__init__</span><span class="nt">(self, f, engine, **kwds)</span>
<span class="g g-Whitespace">   </span><span class="mi">1440</span> 
<span class="g g-Whitespace">   </span><span class="mi">1441</span>         <span class="bp">self</span><span class="o">.</span><span class="n">handles</span><span class="p">:</span> <span class="n">IOHandles</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<span class="ne">-&gt; </span><span class="mi">1442</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_engine</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_engine</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1443</span> 
<span class="g g-Whitespace">   </span><span class="mi">1444</span>     <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py</span> in <span class="ni">_make_engine</span><span class="nt">(self, f, engine)</span>
<span class="g g-Whitespace">   </span><span class="mi">1733</span>                 <span class="k">if</span> <span class="s2">&quot;b&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">mode</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1734</span>                     <span class="n">mode</span> <span class="o">+=</span> <span class="s2">&quot;b&quot;</span>
<span class="ne">-&gt; </span><span class="mi">1735</span>             <span class="bp">self</span><span class="o">.</span><span class="n">handles</span> <span class="o">=</span> <span class="n">get_handle</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1736</span>                 <span class="n">f</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1737</span>                 <span class="n">mode</span><span class="p">,</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/pandas/io/common.py</span> in <span class="ni">get_handle</span><span class="nt">(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)</span>
<span class="g g-Whitespace">    </span><span class="mi">854</span>         <span class="k">if</span> <span class="n">ioargs</span><span class="o">.</span><span class="n">encoding</span> <span class="ow">and</span> <span class="s2">&quot;b&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ioargs</span><span class="o">.</span><span class="n">mode</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">855</span>             <span class="c1"># Encoding</span>
<span class="ne">--&gt; </span><span class="mi">856</span>             <span class="n">handle</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">857</span>                 <span class="n">handle</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">858</span>                 <span class="n">ioargs</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span>

<span class="ne">FileNotFoundError</span>: [Errno 2] No such file or directory: &#39;us-counties.csv&#39;
</pre></div>
</div>
</div>
</div>
<section id="deskripsi-data">
<h4>1. Deskripsi Data<a class="headerlink" href="#deskripsi-data" title="Permalink to this heading">#</a></h4>
<p>waterquality merupakan kumpulan data yang dibuat dari data imajiner kualitas air di lingkungan perkotaan. Dataset ini mencakup data kadar mikroorganisme yang terkandung di dalam air. Data tersebut berisi 21 atribut dan 7999 record, record tersebut diberi label dengan variabel kelas <b><em>is_safe</em></b>, yang memungkinkan klasifikasi data menggunakan nilai 1 (safe atau aman) dan 0 (not_safe atau tidak aman).<br />
data ini saya dapatkan dari Kaggel dengan link berikut :</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Banyaknya data : &quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Banyaknya kolom : &quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Banyaknya data :  7999
Banyaknya kolom :  21
</pre></div>
</div>
</div>
</div>
</section>
<section id="deskripsi-fitur-data">
<h4>2. Deskripsi Fitur Data<a class="headerlink" href="#deskripsi-fitur-data" title="Permalink to this heading">#</a></h4>
<ol class="arabic simple">
<li><p><strong>Aluminium</strong> : Merupakan kandungan aluminium dalam air. berbahaya jika lebih besar dari 2,8. kandungan aluminium yang berlebihan dapat menyebabkan masalah kesehatan, terutama pada sistem saraf.</p></li>
<li><p><strong>Ammonia</strong> : Kandungan ammonia (NH3) dalam air. Amonia adalah gas dengan bau yang tajam dan beracun dalam konsentrasi tinggi. berbahaya jika lebih besar dari 32,5. Kandungan ammonia yang tinggi dalam air dapat menyebabkan kerusakan organisme akuatik dan merusak kualitas air minum.</p></li>
<li><p><strong>Arsenic</strong> : Kandungan arsenik dalam air. Arsenic adalah unsur kimia dalam tabel periodik dengan simbol As dan nomor atom 33. Arsenic dapat ditemukan secara alami di dalam kerak bumi dan digunakan dalam berbagai aplikasi industri, termasuk pembuatan kayu tahan air. arsenic berbahaya jika lebih besar dari 0,01. Kandungan arsenik yang tinggi dalam air minum dapat menyebabkan keracunan dan meningkatkan risiko kanker.</p></li>
<li><p><strong>Barium</strong>: Kandungan barium dalam air. Barium adalah unsur kimia dengan simbol Ba dan nomor atom 56. Barium digunakan dalam industri minyak dan gas, serta dalam radiografi medis. berbahaya jika lebih besar dari 2. Pemaparan jangka panjang terhadap barium dapat menyebabkan kerusakan organ dalam tubuh manusia.</p></li>
<li><p><strong>Cadmium</strong> : Kandungan kadmium dalam air. Cadmium adalah unsur kimia dengan simbol Cd dan nomor atom 48. Cadmium digunakan dalam baterai, cat, dan plastik. berbahaya jika lebih besar dari 0,005. Pemaparan cadmium dapat menyebabkan masalah kesehatan serius, termasuk kerusakan ginjal dan kanker.</p></li>
<li><p><strong>Chloramine</strong> : Kandungan chloramine dalam air. Chloramine adalah senyawa kimia yang terbentuk dari klorin dan amonia. Ini digunakan sebagai desinfektan dalam air minum. berbahaya jika lebih besar dari 4. Paparan kloramine dalam jumlah yang tinggi dapat menyebabkan iritasi mata dan tenggorokan.</p></li>
<li><p><strong>Chromium</strong> : Kandungan kromium dalam air. berbahaya jika lebih besar dari 0,1. Pemaparan kromium VI dapat menyebabkan kerusakan paru-paru, penyakit pernapasan, dan kanker.</p></li>
<li><p><strong>Copper</strong> : Kandungan tembaga dalam air. Copper adalah unsur kimia dengan simbol Cu dan nomor atom 29. Copper digunakan dalam instalasi listrik, pipa, dan peralatan masak. berbahaya jika lebih besar dari 1,3. Kandungan tembaga yang berlebihan dalam air minum dapat menyebabkan gangguan pencernaan dan masalah hati.</p></li>
<li><p><strong>Fluoride</strong> : Kandungan fluoride dalam air. Fluoride adalah ion anorganik yang penting untuk kesehatan gigi. berbahaya jika lebih besar dari 1,5. konsumsi fluoride dalam jumlah yang berlebihan dapat menyebabkan masalah kesehatan gigi dan tulang.</p></li>
<li><p><strong>Bacteria</strong> : Indikator keberadaan bakteri dalam air. Bakteri adalah mikroorganisme yang dapat ditemukan dalam air. berbahaya jika lebih besar dari 0.</p></li>
<li><p><strong>Viruses</strong> : Indikator keberadaan virus dalam air. berbahaya jika lebih besar dari 0</p></li>
<li><p><strong>Lead</strong> : Kandungan timbal dalam air. Lead adalah logam berat yang dapat menyebabkan keracunan, terutama pada anak-anak. berbahaya jika lebih besar dari 0,015. Pemaparan timbal dapat menyebabkan kerusakan otak dan sistem saraf.</p></li>
<li><p><strong>Nitrates</strong> : Kandungan nitrat dalam air. Nitrates adalah senyawa kimia yang dapat ditemukan dalam pupuk dan limbah industriberbahaya jika lebih besar dari 10. Kandungan nitrates yang tinggi dalam air dapat menyebabkan masalah kesehatan, terutama pada bayi.</p></li>
<li><p><strong>Nitrites</strong> : Kandungan nitrit dalam air. nitrites adalah senyawa kimia yang dapat ditemukan dalam pupuk dan limbah industriberbahaya jika lebih besar dari 1. Kandungan nitrites yang tinggi dalam air dapat menyebabkan masalah kesehatan, terutama pada bayi.</p></li>
<li><p><strong>Mercury</strong> : Kandungan merkuri dalam air. Mercury adalah logam berat yang dapat mengakumulasi dalam organisme hidup dan menyebabkan keracunan. berbahaya jika lebih besar dari 0,002. Pemaparan merkuri dapat merusak otak, ginjal, dan sistem saraf.</p></li>
<li><p><strong>Perchlorate</strong> : Kandungan perchlorate dalam air. Perchlorate adalah senyawa kimia yang digunakan dalam bahan peledak dan propelan roket. Pemaparan perchlorate dapat mengganggu fungsi tiroid. berbahaya jika lebih besar dari 56</p></li>
<li><p><strong>Radium</strong> : Kandungan radium dalam air. Radium adalah unsur radioaktif yang dapat ditemukan secara alami dalam tanah dan air. Paparan radium dapat meningkatkan risiko kanker. berbahaya jika lebih besar dari 5</p></li>
<li><p><strong>Selenium</strong> : Kandungan selenium dalam air. berbahaya jika lebih besar dari 0,5. konsumsi selenium yang berlebihan dapat menyebabkan masalah kesehatan, termasuk kerusakan saraf.</p></li>
<li><p><strong>Silver</strong> : Kandungan perak dalam air. berbahaya jika lebih besar dari 0,1. Konsumsi perak dalam jumlah yang berlebihan dapat menyebabkan argyria, kondisi di mana kulit manusia berubah menjadi warna biru keabu-abuan.</p></li>
<li><p><strong>Uranium</strong> : Kandungan uranium dalam air. Uranium adalah unsur radioaktif yang dapat ditemukan secara alami dalam batuan dan air. Paparan uranium dapat meningkatkan risiko kanker dan masalah ginjal. berbahaya jika lebih besar dari 0,3</p></li>
<li><p><strong>Is_safe</strong> : Kolom ini adalah label atau target variabel yang menunjukkan apakah sampel air tersebut aman untuk dikonsumsi atau tidak. class attribute {0 - not safe, 1 - safe}</p></li>
</ol>
<p>fitur di atas ini mencerminkan kandungan berbagai mikroorganisme dalam air. Dalam setiap fitur atau kandungan yang ada dalam air tersebut memiliki batasan. jika kandungan mikroorganisme melebihi nilai-nilai batasan ini, air dianggap tidak aman untuk konsumsi manusia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;flouride&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;lead&#39;,
       &#39;nitrates&#39;, &#39;nitrites&#39;, &#39;mercury&#39;, &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;,
       &#39;silver&#39;, &#39;uranium&#39;, &#39;is_safe&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="deskripsi-tipe-data-fitur">
<h4>3. Deskripsi Tipe Data Fitur<a class="headerlink" href="#deskripsi-tipe-data-fitur" title="Permalink to this heading">#</a></h4>
<p>Berikut adalah analisis tipe data untuk setiap kolom beserta alasannya:</p>
<ol class="arabic simple">
<li><p>aluminium: Tipe data rasio. Kandungan aluminium dalam air memiliki nol yang bermakna, dan perbandingan antara dua nilai memiliki arti yang jelas (misalnya, 2 kali lipat).</p></li>
<li><p>ammonia: Tipe data rasio. Kandungan ammonia dalam air juga memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>arsenic: Tipe data rasio. Kandungan arsenik dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>barium: Tipe data rasio. Kandungan barium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>cadmium: Tipe data rasio. Kandungan cadmium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>chloramine: Tipe data rasio. Kandungan chloramine dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>chromium: Tipe data rasio. Kandungan chromium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>copper: Tipe data rasio. Kandungan copper dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>flouride: Tipe data rasio. Kandungan flouride dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>bacteria: Tipe data rasio. Kandungan bakteri dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>viruses: Tipe data rasio. Kandungan virus dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>lead: Tipe data rasio. Kandungan lead dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>nitrates: Tipe data rasio. Kandungan nitrates dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>nitrites: Tipe data rasio. Kandungan nitrites dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>mercury: Tipe data rasio. Kandungan mercury dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>perchlorate: Tipe data rasio. Kandungan perchlorate dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>radium: Tipe data rasio. Kandungan radium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>selenium: Tipe data rasio. Kandungan selenium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>silver: Tipe data rasio. Kandungan silver dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>uranium: Tipe data rasio. Kandungan uranium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>is_safe: Tipe data nominal. Variabel target ini merupakan label kategori yang menunjukkan apakah air layak diminum atau tidak. Ini merupakan tipe data kategorikal dengan dua kategori yang bersifat nominal.</p></li>
</ol>
</section>
<section id="identifikasi-missing-value">
<h4>4. Identifikasi Missing Value<a class="headerlink" href="#identifikasi-missing-value" title="Permalink to this heading">#</a></h4>
<p>Pada dataset ini tidak ditemukan data yang mengalami missing value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menghitung apakah ada nilai yang hilang dalam setiap kolom</span>
<span class="n">missing_values</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>

<span class="c1"># Menampilkan hasil</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Apakah ada nilai yang hilang dalam setiap kolom:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">missing_values</span><span class="p">)</span>
<span class="n">nan_data</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data dengan nilai NaN:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nan_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Apakah ada nilai yang hilang dalam setiap kolom:
aluminium      False
ammonia        False
arsenic        False
barium         False
cadmium        False
chloramine     False
chromium       False
copper         False
flouride       False
bacteria       False
viruses        False
lead           False
nitrates       False
nitrites       False
mercury        False
perchlorate    False
radium         False
selenium       False
silver         False
uranium        False
is_safe        False
dtype: bool
Data dengan nilai NaN:
Empty DataFrame
Columns: [aluminium, ammonia, arsenic, barium, cadmium, chloramine, chromium, copper, flouride, bacteria, viruses, lead, nitrates, nitrites, mercury, perchlorate, radium, selenium, silver, uranium, is_safe]
Index: []

[0 rows x 21 columns]
</pre></div>
</div>
</div>
</div>
</section>
<section id="identifikasi-duplikasi-data">
<h4>5. Identifikasi Duplikasi Data<a class="headerlink" href="#identifikasi-duplikasi-data" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">jumlah_duplikat</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">duplicated</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="c1"># Menampilkan jumlah data yang duplikat</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah data yang duplikat:&quot;</span><span class="p">,</span> <span class="n">jumlah_duplikat</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah data yang duplikat: 0
</pre></div>
</div>
</div>
</div>
</section>
<section id="explorasi-data-menampilkan-grafik">
<h4>6. Explorasi Data (Menampilkan Grafik)<a class="headerlink" href="#explorasi-data-menampilkan-grafik" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Histogram Sebaran Frekuensi Data Setiap Kolom</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#distribution data</span>
<span class="n">df</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/faa991558a2ec9c73199c857cf88aaeee7b884afac2f7d42b666b6e8fcb6d3f2.png" src="../_images/faa991558a2ec9c73199c857cf88aaeee7b884afac2f7d42b666b6e8fcb6d3f2.png" />
</div>
</div>
<ul class="simple">
<li><p>Boxplot Setiap Kolom (Nilai Maksimal, Nilai Minimal, Median, Standar Devisiasi)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a list of numerical features and plot them</span>
<span class="n">list_of_num_features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">])</span>  <span class="c1"># DataFrame of numerical features</span>
<span class="n">palette_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;#E68753&#39;</span><span class="p">,</span> <span class="s1">&#39;#409996&#39;</span><span class="p">]</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;axes.facecolor&#39;</span><span class="p">:</span><span class="s1">&#39;#ECECEC&#39;</span><span class="p">})</span>

<span class="c1"># Mengatur tata letak subplot</span>
<span class="n">num_rows</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">num_cols</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Flatten array of subplots for ease of indexing</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">list_of_num_features</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>  <span class="c1"># Mengambil subplot yang sesuai</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">palette_features</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>

<span class="c1"># Sembunyikan subplot yang tidak digunakan</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">list_of_num_features</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span> <span class="n">num_rows</span> <span class="o">*</span> <span class="n">num_cols</span><span class="p">):</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">delaxes</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="c1"># Atur tata letak dan tampilkan plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e40d5bf2f6501ac6d077d415d3ac396457969fb2fbec4f1f842d07b9f269dced.png" src="../_images/e40d5bf2f6501ac6d077d415d3ac396457969fb2fbec4f1f842d07b9f269dced.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Correlation Plot of Water Quality Parameters&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1c022b25a23c9fb2de7c72a55951705271835727b9c4f5ebbdaa29d49315ad7e.png" src="../_images/1c022b25a23c9fb2de7c72a55951705271835727b9c4f5ebbdaa29d49315ad7e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;whitegrid&#39;</span><span class="p">)</span>

<span class="c1"># Plot histograms for the distribution of all columns</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="n">data_columns</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">data_columns</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">)</span>

<span class="c1"># Adjust the number of rows and columns in the subplot grid for better visualization</span>
<span class="n">num_rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_columns</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_columns</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span>
<span class="n">num_cols</span> <span class="o">=</span> <span class="mi">2</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_columns</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Distribution of </span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Original Distribution&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/6bf50989e705aa2c13baf2a4d6880319744d903aeeb3adbafd6be7b2b7b7684c.png" src="../_images/6bf50989e705aa2c13baf2a4d6880319744d903aeeb3adbafd6be7b2b7b7684c.png" />
</div>
</div>
</section>
</section>
<section id="center-pre-processing-center">
<h3><center><strong>——Pre Processing——</strong></center><a class="headerlink" href="#center-pre-processing-center" title="Permalink to this heading">#</a></h3>
<center>merupakan sebuah memperbaiki sebuah data</center><section id="menemukan-data-outlier">
<h4>1. Menemukan Data Outlier<a class="headerlink" href="#menemukan-data-outlier" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Fungsi untuk mendeteksi outlier menggunakan z-score</span>
<span class="k">def</span> <span class="nf">detect_outliers</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">z_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">zscore</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
    <span class="n">row_outliers</span><span class="p">,</span> <span class="n">col_outliers</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">z_scores</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">row_outliers</span><span class="p">,</span> <span class="n">col_outliers</span><span class="p">))</span>

<span class="c1"># Mendeteksi outlier</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">detect_outliers</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="k">if</span> <span class="n">outliers</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Outlier(s) terdeteksi pada baris dan kolom berikut:&quot;</span><span class="p">)</span>

    <span class="c1"># Menghitung jumlah outlier</span>
    <span class="n">total_outliers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">outliers</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total outlier: </span><span class="si">{</span><span class="n">total_outliers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># Menghapus outlier</span>
    <span class="n">data_no_outliers</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">outliers</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">data_no_outliers</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
            <span class="n">data_no_outliers</span> <span class="o">=</span> <span class="n">data_no_outliers</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">row</span><span class="p">)</span>

    <span class="c1"># Menghitung jumlah baris tanpa outlier</span>
    <span class="n">rows_without_outliers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_no_outliers</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah baris tanpa outlier: </span><span class="si">{</span><span class="n">rows_without_outliers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tidak ada outlier dalam data.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Outlier(s) terdeteksi pada baris dan kolom berikut:
Total outlier: 391
Jumlah baris tanpa outlier: 7617
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menghitung jumlah target pada data tanpa outlier</span>
<span class="n">target_no_outliers</span> <span class="o">=</span> <span class="n">data_no_outliers</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah target pada data tanpa outlier:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">target_no_outliers</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah target pada data tanpa outlier:
0    6769
1     848
Name: is_safe, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_no_outliers</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;data_bersih.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="balancing-class-data">
<h4>2. Balancing Class Data<a class="headerlink" href="#balancing-class-data" title="Permalink to this heading">#</a></h4>
<p>Balancing kelas pada dataset ini menggunakan teknik <em>Balancing class data menggunakan Random Over-Sampling With imblearn</em>
Random Over-Sampling With imblearn adalah salah satu teknik yang digunakan untuk menangani ketidakseimbangan kelas. Dalam metode ini, jumlah sampel dalam kelas minoritas ditingkatkan dengan menambahkan salinan acak dari sampel yang sudah ada dalam kelas tersebut. Metode Random Over-Sampling memungkinkan untuk mengatasi ketidakseimbangan kelas tanpa menghapus data dari kelas mayoritas, sehingga tidak ada informasi yang hilang dalam prosesnya.</p>
<ul class="simple">
<li><p>Perbandingan jumlah kelas awal</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data_bersih.xlsx&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;is_safe&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1"># sebaran class</span>
<span class="n">class_0</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">class_1</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;class 0 (Not Safe) :&#39;</span><span class="p">,</span> <span class="n">class_0</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;class 1 (Safe)     :&#39;</span><span class="p">,</span> <span class="n">class_1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/21c54b110cf07de103825283c469986fd71298f744dc6c3db6572d6af8456215.png" src="../_images/21c54b110cf07de103825283c469986fd71298f744dc6c3db6572d6af8456215.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>class 0 (Not Safe) : (6769, 21)
class 1 (Safe)     : (848, 21)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Proses Balancing Data</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import library</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">RandomOverSampler</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="c1"># Separate features (X) and target variable (y)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span>

<span class="c1"># Print original class distribution</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sebaran Data :&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sebaran Data Kelas Awal:&#39;</span><span class="p">,</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="c1"># Initialize RandomOverSampler</span>
<span class="n">ros</span> <span class="o">=</span> <span class="n">RandomOverSampler</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Apply Random Over-Sampling to balance the classes</span>
<span class="n">X_ros</span><span class="p">,</span> <span class="n">y_ros</span> <span class="o">=</span> <span class="n">ros</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Print resampled class distribution</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sebaran Data Kelas Setelah Balancing:&#39;</span><span class="p">,</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y_ros</span><span class="p">))</span>

<span class="c1"># Menampilkan jumlah data setelah balancing sampling</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Jumlah keseluruhan data setelah balancing sampling :&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Features (X_ros) shape:&#39;</span><span class="p">,</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Target (y_ros) shape:&#39;</span><span class="p">,</span> <span class="n">y_ros</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">#visualisasi perbandingan data kelas</span>
<span class="c1"># Plot original class distribution</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;is_safe&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Original Class&#39;</span><span class="p">)</span>

<span class="c1"># Plot resampled class distribution after Random Over-Sampling</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;is_safe&#39;</span><span class="p">:</span> <span class="n">y_ros</span><span class="p">}),</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;is_safe&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Random Over-Sampling With imblearn&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sebaran Data :
Sebaran Data Kelas Awal: Counter({0: 6769, 1: 848})
Sebaran Data Kelas Setelah Balancing: Counter({1: 6769, 0: 6769})

Jumlah keseluruhan data setelah balancing sampling :
Features (X_ros) shape: (13538, 20)
Target (y_ros) shape: (13538,)
</pre></div>
</div>
<img alt="../_images/aa287ebf6e2130ea7c88875d3ed48492c82a43b071cd1dfe75187df63c1a0ab9.png" src="../_images/aa287ebf6e2130ea7c88875d3ed48492c82a43b071cd1dfe75187df63c1a0ab9.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mengonversi array NumPy ke DataFrame pandas</span>
<span class="n">df_X_ros</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_ros</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">df_y_ros</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y_ros</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">])</span>
<span class="c1"># Menggabungkan DataFrame X_ros dan y_ros</span>
<span class="n">df_resampled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_X_ros</span><span class="p">,</span> <span class="n">df_y_ros</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Menyimpan DataFrame ke dalam file Excel</span>
<span class="n">df_resampled</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;data_balancing.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="seleksi-fitur">
<h5>3. Seleksi Fitur<a class="headerlink" href="#seleksi-fitur" title="Permalink to this heading">#</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menghitung Information Gain untuk setiap fitur</span>
<span class="n">information_gains</span> <span class="o">=</span> <span class="n">mutual_info_classif</span><span class="p">(</span><span class="n">X_ros</span><span class="p">,</span> <span class="n">y_ros</span><span class="p">)</span>

<span class="c1"># Menyusun hasil ke dalam DataFrame untuk analisis</span>
<span class="n">feature_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;feature&#39;</span><span class="p">:</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="s1">&#39;information_gain&#39;</span><span class="p">:</span> <span class="n">information_gains</span><span class="p">})</span>
<span class="n">feature_scores</span> <span class="o">=</span> <span class="n">feature_scores</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;information_gain&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Menampilkan hasil Information Gain untuk setiap fitur</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feature_scores</span><span class="p">)</span>

<span class="c1"># Plotting bar plot untuk perbandingan Information Gain</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">feature_scores</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">],</span> <span class="n">feature_scores</span><span class="p">[</span><span class="s1">&#39;information_gain&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightgreen&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Information Gain&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Top 10 Features by Information Gain&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>        feature  information_gain
15  perchlorate          0.316766
1       ammonia          0.300024
0     aluminium          0.213614
12     nitrates          0.203453
4       cadmium          0.178675
5    chloramine          0.176580
16       radium          0.133952
2       arsenic          0.094927
3        barium          0.086180
6      chromium          0.084879
13     nitrites          0.078707
7        copper          0.031218
11         lead          0.030660
10      viruses          0.028403
18       silver          0.026798
8      flouride          0.026413
9      bacteria          0.024090
19      uranium          0.009469
14      mercury          0.006788
17     selenium          0.003500
</pre></div>
</div>
<img alt="../_images/e6b7762dac20dbadf404da2e9cfecb372860c877f3d7b10dd67bc6ecd1d50df2.png" src="../_images/e6b7762dac20dbadf404da2e9cfecb372860c877f3d7b10dd67bc6ecd1d50df2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">korelasi_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">korelasi_data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aluminium</th>
      <th>ammonia</th>
      <th>arsenic</th>
      <th>barium</th>
      <th>cadmium</th>
      <th>chloramine</th>
      <th>chromium</th>
      <th>copper</th>
      <th>flouride</th>
      <th>bacteria</th>
      <th>...</th>
      <th>lead</th>
      <th>nitrates</th>
      <th>nitrites</th>
      <th>mercury</th>
      <th>perchlorate</th>
      <th>radium</th>
      <th>selenium</th>
      <th>silver</th>
      <th>uranium</th>
      <th>is_safe</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>aluminium</th>
      <td>1.000000</td>
      <td>0.052620</td>
      <td>0.197743</td>
      <td>0.281000</td>
      <td>-0.120147</td>
      <td>0.366124</td>
      <td>0.353400</td>
      <td>0.157401</td>
      <td>-0.009578</td>
      <td>-0.066423</td>
      <td>...</td>
      <td>0.021714</td>
      <td>0.011929</td>
      <td>0.228204</td>
      <td>-0.004285</td>
      <td>0.359867</td>
      <td>0.229690</td>
      <td>0.004749</td>
      <td>0.324705</td>
      <td>0.005346</td>
      <td>0.352426</td>
    </tr>
    <tr>
      <th>ammonia</th>
      <td>0.052620</td>
      <td>1.000000</td>
      <td>0.048631</td>
      <td>0.068572</td>
      <td>-0.009879</td>
      <td>0.106141</td>
      <td>0.123608</td>
      <td>0.013056</td>
      <td>-0.028137</td>
      <td>0.063223</td>
      <td>...</td>
      <td>-0.034971</td>
      <td>0.007193</td>
      <td>-0.065902</td>
      <td>0.018598</td>
      <td>0.093548</td>
      <td>0.045987</td>
      <td>0.032309</td>
      <td>0.072125</td>
      <td>0.016762</td>
      <td>-0.023530</td>
    </tr>
    <tr>
      <th>arsenic</th>
      <td>0.197743</td>
      <td>0.048631</td>
      <td>1.000000</td>
      <td>0.341812</td>
      <td>0.317161</td>
      <td>0.353721</td>
      <td>0.309112</td>
      <td>-0.041724</td>
      <td>0.001937</td>
      <td>0.043658</td>
      <td>...</td>
      <td>-0.093871</td>
      <td>0.030767</td>
      <td>0.292210</td>
      <td>-0.014410</td>
      <td>0.318377</td>
      <td>0.203057</td>
      <td>0.000296</td>
      <td>0.303865</td>
      <td>0.001348</td>
      <td>-0.109699</td>
    </tr>
    <tr>
      <th>barium</th>
      <td>0.281000</td>
      <td>0.068572</td>
      <td>0.341812</td>
      <td>1.000000</td>
      <td>-0.061423</td>
      <td>0.448267</td>
      <td>0.416904</td>
      <td>0.062726</td>
      <td>-0.021346</td>
      <td>0.107645</td>
      <td>...</td>
      <td>-0.041571</td>
      <td>-0.008805</td>
      <td>0.304819</td>
      <td>0.006374</td>
      <td>0.464943</td>
      <td>0.280563</td>
      <td>0.039059</td>
      <td>0.433037</td>
      <td>-0.005683</td>
      <td>0.094403</td>
    </tr>
    <tr>
      <th>cadmium</th>
      <td>-0.120147</td>
      <td>-0.009879</td>
      <td>0.317161</td>
      <td>-0.061423</td>
      <td>1.000000</td>
      <td>-0.170364</td>
      <td>-0.178857</td>
      <td>-0.112473</td>
      <td>0.000783</td>
      <td>-0.101460</td>
      <td>...</td>
      <td>-0.037134</td>
      <td>0.018778</td>
      <td>-0.029818</td>
      <td>-0.017386</td>
      <td>-0.173508</td>
      <td>-0.116322</td>
      <td>0.009509</td>
      <td>-0.175347</td>
      <td>-0.005964</td>
      <td>-0.247923</td>
    </tr>
    <tr>
      <th>chloramine</th>
      <td>0.366124</td>
      <td>0.106141</td>
      <td>0.353721</td>
      <td>0.448267</td>
      <td>-0.170364</td>
      <td>1.000000</td>
      <td>0.573332</td>
      <td>0.113769</td>
      <td>0.006347</td>
      <td>0.167030</td>
      <td>...</td>
      <td>-0.038662</td>
      <td>-0.001632</td>
      <td>0.375661</td>
      <td>-0.017468</td>
      <td>0.596632</td>
      <td>0.396282</td>
      <td>0.017087</td>
      <td>0.534064</td>
      <td>-0.007886</td>
      <td>0.194040</td>
    </tr>
    <tr>
      <th>chromium</th>
      <td>0.353400</td>
      <td>0.123608</td>
      <td>0.309112</td>
      <td>0.416904</td>
      <td>-0.178857</td>
      <td>0.573332</td>
      <td>1.000000</td>
      <td>0.117146</td>
      <td>-0.001789</td>
      <td>0.150157</td>
      <td>...</td>
      <td>-0.046904</td>
      <td>-0.015570</td>
      <td>0.335985</td>
      <td>-0.020876</td>
      <td>0.536018</td>
      <td>0.317260</td>
      <td>0.035593</td>
      <td>0.516621</td>
      <td>-0.009789</td>
      <td>0.190147</td>
    </tr>
    <tr>
      <th>copper</th>
      <td>0.157401</td>
      <td>0.013056</td>
      <td>-0.041724</td>
      <td>0.062726</td>
      <td>-0.112473</td>
      <td>0.113769</td>
      <td>0.117146</td>
      <td>1.000000</td>
      <td>0.012131</td>
      <td>0.163113</td>
      <td>...</td>
      <td>0.118681</td>
      <td>0.005911</td>
      <td>0.165186</td>
      <td>0.019474</td>
      <td>0.104806</td>
      <td>0.020809</td>
      <td>-0.002150</td>
      <td>0.084884</td>
      <td>0.009623</td>
      <td>0.024240</td>
    </tr>
    <tr>
      <th>flouride</th>
      <td>-0.009578</td>
      <td>-0.028137</td>
      <td>0.001937</td>
      <td>-0.021346</td>
      <td>0.000783</td>
      <td>0.006347</td>
      <td>-0.001789</td>
      <td>0.012131</td>
      <td>1.000000</td>
      <td>0.013033</td>
      <td>...</td>
      <td>0.014569</td>
      <td>-0.007492</td>
      <td>-0.016521</td>
      <td>-0.000944</td>
      <td>-0.013628</td>
      <td>0.006804</td>
      <td>0.026893</td>
      <td>0.012543</td>
      <td>0.018271</td>
      <td>0.004660</td>
    </tr>
    <tr>
      <th>bacteria</th>
      <td>-0.066423</td>
      <td>0.063223</td>
      <td>0.043658</td>
      <td>0.107645</td>
      <td>-0.101460</td>
      <td>0.167030</td>
      <td>0.150157</td>
      <td>0.163113</td>
      <td>0.013033</td>
      <td>1.000000</td>
      <td>...</td>
      <td>-0.026765</td>
      <td>-0.033752</td>
      <td>0.260786</td>
      <td>-0.005576</td>
      <td>0.159883</td>
      <td>0.103841</td>
      <td>-0.005239</td>
      <td>0.160239</td>
      <td>0.046747</td>
      <td>-0.025905</td>
    </tr>
    <tr>
      <th>viruses</th>
      <td>-0.071626</td>
      <td>0.103633</td>
      <td>0.011008</td>
      <td>-0.003399</td>
      <td>0.013971</td>
      <td>0.004336</td>
      <td>0.000894</td>
      <td>0.011215</td>
      <td>0.019335</td>
      <td>0.614093</td>
      <td>...</td>
      <td>0.021774</td>
      <td>-0.043987</td>
      <td>-0.091647</td>
      <td>0.010505</td>
      <td>0.004360</td>
      <td>-0.023015</td>
      <td>-0.036711</td>
      <td>0.014987</td>
      <td>0.058924</td>
      <td>-0.098602</td>
    </tr>
    <tr>
      <th>lead</th>
      <td>0.021714</td>
      <td>-0.034971</td>
      <td>-0.093871</td>
      <td>-0.041571</td>
      <td>-0.037134</td>
      <td>-0.038662</td>
      <td>-0.046904</td>
      <td>0.118681</td>
      <td>0.014569</td>
      <td>-0.026765</td>
      <td>...</td>
      <td>1.000000</td>
      <td>0.037543</td>
      <td>-0.050761</td>
      <td>-0.007391</td>
      <td>-0.029910</td>
      <td>-0.049770</td>
      <td>0.030195</td>
      <td>-0.053816</td>
      <td>-0.009605</td>
      <td>-0.013376</td>
    </tr>
    <tr>
      <th>nitrates</th>
      <td>0.011929</td>
      <td>0.007193</td>
      <td>0.030767</td>
      <td>-0.008805</td>
      <td>0.018778</td>
      <td>-0.001632</td>
      <td>-0.015570</td>
      <td>0.005911</td>
      <td>-0.007492</td>
      <td>-0.033752</td>
      <td>...</td>
      <td>0.037543</td>
      <td>1.000000</td>
      <td>0.017912</td>
      <td>-0.018101</td>
      <td>-0.010221</td>
      <td>-0.021269</td>
      <td>0.048323</td>
      <td>0.007562</td>
      <td>0.001679</td>
      <td>-0.067341</td>
    </tr>
    <tr>
      <th>nitrites</th>
      <td>0.228204</td>
      <td>-0.065902</td>
      <td>0.292210</td>
      <td>0.304819</td>
      <td>-0.029818</td>
      <td>0.375661</td>
      <td>0.335985</td>
      <td>0.165186</td>
      <td>-0.016521</td>
      <td>0.260786</td>
      <td>...</td>
      <td>-0.050761</td>
      <td>0.017912</td>
      <td>1.000000</td>
      <td>-0.014922</td>
      <td>0.341457</td>
      <td>0.269611</td>
      <td>0.018362</td>
      <td>0.328639</td>
      <td>-0.010927</td>
      <td>0.049738</td>
    </tr>
    <tr>
      <th>mercury</th>
      <td>-0.004285</td>
      <td>0.018598</td>
      <td>-0.014410</td>
      <td>0.006374</td>
      <td>-0.017386</td>
      <td>-0.017468</td>
      <td>-0.020876</td>
      <td>0.019474</td>
      <td>-0.000944</td>
      <td>-0.005576</td>
      <td>...</td>
      <td>-0.007391</td>
      <td>-0.018101</td>
      <td>-0.014922</td>
      <td>1.000000</td>
      <td>0.007367</td>
      <td>0.029057</td>
      <td>0.032252</td>
      <td>0.006447</td>
      <td>0.033361</td>
      <td>-0.035835</td>
    </tr>
    <tr>
      <th>perchlorate</th>
      <td>0.359867</td>
      <td>0.093548</td>
      <td>0.318377</td>
      <td>0.464943</td>
      <td>-0.173508</td>
      <td>0.596632</td>
      <td>0.536018</td>
      <td>0.104806</td>
      <td>-0.013628</td>
      <td>0.159883</td>
      <td>...</td>
      <td>-0.029910</td>
      <td>-0.010221</td>
      <td>0.341457</td>
      <td>0.007367</td>
      <td>1.000000</td>
      <td>0.377788</td>
      <td>0.017972</td>
      <td>0.515054</td>
      <td>-0.003549</td>
      <td>0.084343</td>
    </tr>
    <tr>
      <th>radium</th>
      <td>0.229690</td>
      <td>0.045987</td>
      <td>0.203057</td>
      <td>0.280563</td>
      <td>-0.116322</td>
      <td>0.396282</td>
      <td>0.317260</td>
      <td>0.020809</td>
      <td>0.006804</td>
      <td>0.103841</td>
      <td>...</td>
      <td>-0.049770</td>
      <td>-0.021269</td>
      <td>0.269611</td>
      <td>0.029057</td>
      <td>0.377788</td>
      <td>1.000000</td>
      <td>0.034953</td>
      <td>0.358417</td>
      <td>0.018156</td>
      <td>0.066105</td>
    </tr>
    <tr>
      <th>selenium</th>
      <td>0.004749</td>
      <td>0.032309</td>
      <td>0.000296</td>
      <td>0.039059</td>
      <td>0.009509</td>
      <td>0.017087</td>
      <td>0.035593</td>
      <td>-0.002150</td>
      <td>0.026893</td>
      <td>-0.005239</td>
      <td>...</td>
      <td>0.030195</td>
      <td>0.048323</td>
      <td>0.018362</td>
      <td>0.032252</td>
      <td>0.017972</td>
      <td>0.034953</td>
      <td>1.000000</td>
      <td>-0.013578</td>
      <td>-0.018451</td>
      <td>-0.031197</td>
    </tr>
    <tr>
      <th>silver</th>
      <td>0.324705</td>
      <td>0.072125</td>
      <td>0.303865</td>
      <td>0.433037</td>
      <td>-0.175347</td>
      <td>0.534064</td>
      <td>0.516621</td>
      <td>0.084884</td>
      <td>0.012543</td>
      <td>0.160239</td>
      <td>...</td>
      <td>-0.053816</td>
      <td>0.007562</td>
      <td>0.328639</td>
      <td>0.006447</td>
      <td>0.515054</td>
      <td>0.358417</td>
      <td>-0.013578</td>
      <td>1.000000</td>
      <td>0.009674</td>
      <td>0.107180</td>
    </tr>
    <tr>
      <th>uranium</th>
      <td>0.005346</td>
      <td>0.016762</td>
      <td>0.001348</td>
      <td>-0.005683</td>
      <td>-0.005964</td>
      <td>-0.007886</td>
      <td>-0.009789</td>
      <td>0.009623</td>
      <td>0.018271</td>
      <td>0.046747</td>
      <td>...</td>
      <td>-0.009605</td>
      <td>0.001679</td>
      <td>-0.010927</td>
      <td>0.033361</td>
      <td>-0.003549</td>
      <td>0.018156</td>
      <td>-0.018451</td>
      <td>0.009674</td>
      <td>1.000000</td>
      <td>-0.076820</td>
    </tr>
    <tr>
      <th>is_safe</th>
      <td>0.352426</td>
      <td>-0.023530</td>
      <td>-0.109699</td>
      <td>0.094403</td>
      <td>-0.247923</td>
      <td>0.194040</td>
      <td>0.190147</td>
      <td>0.024240</td>
      <td>0.004660</td>
      <td>-0.025905</td>
      <td>...</td>
      <td>-0.013376</td>
      <td>-0.067341</td>
      <td>0.049738</td>
      <td>-0.035835</td>
      <td>0.084343</td>
      <td>0.066105</td>
      <td>-0.031197</td>
      <td>0.107180</td>
      <td>-0.076820</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>21 rows × 21 columns</p>
</div></div></div>
</div>
</section>
</section>
<section id="normalisasi-dan-split-data">
<h4>4. Normalisasi dan Split Data<a class="headerlink" href="#normalisasi-dan-split-data" title="Permalink to this heading">#</a></h4>
<ul>
<li><p><b>Normalisasi Min-Max</b> adalah salah satu teknik preprocessing data yang digunakan untuk mengubah skala data numerik ke dalam rentang tertentu, biasanya dari 0 hingga 1. Tujuan utama dari normalisasi Min-Max adalah untuk menjaga skala data sehingga nilai-nilai dari berbagai fitur atau variabel memiliki rentang yang serupa, sehingga model pembelajaran mesin dapat bekerja lebih efisien dan tidak terpengaruh oleh perbedaan skala. Berikut adalah langkah-langkah umum dalam normalisasi Min-Max:</p>
<ul>
<li><p>Pilih Rentang Normalisasi: Biasanya, rentang normalisasi adalah antara 0 hingga 1, tetapi Anda juga dapat memilih rentang lain, tergantung pada kebutuhan Anda.</p></li>
<li><p>Hitung Nilai Minimum dan Maksimum: Temukan nilai minimum (Min) dan maksimum (Max) dari setiap fitur atau variabel dalam dataset Anda.</p></li>
<li><p>Gunakan Rumus Normalisasi Min-Max: Untuk setiap nilai dalam fitur, gunakan rumus berikut untuk menghitung nilai yang telah dinormalisasi (X_normalized):
X_normalized = (X - Min) / (Max - Min)</p>
<p>di mana:</p>
<ul class="simple">
<li><p>X adalah nilai asli dalam fitur.</p></li>
<li><p>Min adalah nilai minimum dalam fitur.</p></li>
<li><p>Max adalah nilai maksimum dalam fitur.</p></li>
</ul>
</li>
<li><p>Terapkan Normalisasi:</b> Terapkan rumus normalisasi Min-Max pada semua nilai dalam setiap fitur, sehingga semua fitur memiliki nilai yang telah dinormalisasi dalam rentang yang dipilih</p></li>
</ul>
</li>
<li><p><b>Pemisahan dataset</b>, atau splitting dataset, adalah proses membagi dataset menjadi dua atau lebih subset yang berbeda. Tujuan utama dari pemisahan dataset adalah untuk memungkinkan evaluasi dan pengujian model pembelajaran mesin dengan benar.</p>
<ul class="simple">
<li><p>Memisahkan Fitur dan Target: Dataset asli (data) dibagi menjadi dua bagian: fitur (X) dan target (Y). Fitur adalah kolom data yang akan digunakan sebagai input untuk model pembelajaran mesin, sedangkan target adalah kolom yang akan diprediksi oleh model. Dalam kasus ini, kolom ‘NObeyesdad’ adalah target, sementara kolom lainnya dihilangkan (drop) dari fitur.</p></li>
<li><p>Memisahkan Data Latihan dan Data Uji: Fungsi train_test_split digunakan untuk membagi dataset menjadi data latihan (X_train dan Y_train) dan data uji (X_test dan Y_test). Parameter test_size = 0.2 menentukan bahwa 20% dari data akan menjadi data uji, sementara 80% sisanya akan menjadi data latihan. Parameter random_state = 42 digunakan untuk mengatur seed (bilangan acak awal) sehingga pembagian dataset ini dapat direproduksi jika diperlukan.</p></li>
<li><p>Menampilkan Informasi Dataset: Kode selanjutnya mencetak jumlah total data dalam dataset (X.shape[0]), jumlah data latihan (X_train.shape[0]), dan jumlah data uji (X_test.shape[0]). Ini membantu Anda memahami berapa banyak data yang digunakan untuk melatih model dan seberapa banyak data yang akan digunakan untuk menguji model.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membagi data menjadi data training dan data testing</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_ros</span><span class="p">,</span> <span class="n">y_ros</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah Data : &quot;</span><span class="p">,</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data Latih : &quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data Uji   : &quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Normalisasi Min-Max pada data training</span>
<span class="n">minmax_scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X_train_minmax</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_minmax</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">joblib</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">minmax_scaler</span><span class="p">,</span> <span class="s1">&#39;scaler.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah Data :  13538
Data Latih :  10830
Data Uji   :  2708
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;scaler.pkl&#39;]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="center-pembuatan-model-center">
<h3><center><strong>Pembuatan Model</strong></center><a class="headerlink" href="#center-pembuatan-model-center" title="Permalink to this heading">#</a></h3>
<center>merupakan proses pembuatan model klasifikasi untuk klasifikasi data</center><section id="random-forest">
<h4>1. Random Forest<a class="headerlink" href="#random-forest" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">joblib</span>

<span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_minmax</span><span class="p">)</span>

    <span class="c1"># Mendapatkan nama fitur terpilih</span>
    <span class="n">selected_feature_names</span> <span class="o">=</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="c1"># Membuat model Random Forest</span>
    <span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">rf_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">y_pred_rf</span> <span class="o">=</span> <span class="n">rf_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model Random Forest</span>
    <span class="n">accuracy_rf</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_rf</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy Random Forest with top </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> features: </span><span class="si">{</span><span class="n">accuracy_rf</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_rf</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_rf</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">selected_feature_names</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">rf_model</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Accuracy:&quot;</span><span class="p">,</span> <span class="n">best_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best k:&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Selected Feature Names:&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>

<span class="c1"># Menyimpan model yang telah dilatih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span> <span class="s1">&#39;modelrandomforest.pkl&#39;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fiturrandomforest.pkl&#39;</span><span class="p">)</span>

<span class="n">accuracy_rf</span> <span class="o">=</span> <span class="n">best_accuracy</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy Random Forest with top 20 features: 98.6706%
Accuracy Random Forest with top 19 features: 98.8922%
Accuracy Random Forest with top 18 features: 99.0030%
Accuracy Random Forest with top 17 features: 99.0768%
Accuracy Random Forest with top 16 features: 99.0768%
Accuracy Random Forest with top 15 features: 98.7075%
Accuracy Random Forest with top 14 features: 98.6706%
Accuracy Random Forest with top 13 features: 98.4121%
Accuracy Random Forest with top 12 features: 98.5598%
Accuracy Random Forest with top 11 features: 98.7075%
Accuracy Random Forest with top 10 features: 98.4860%
Accuracy Random Forest with top 9 features: 98.5598%
Accuracy Random Forest with top 8 features: 98.2644%
Accuracy Random Forest with top 7 features: 96.8612%
Accuracy Random Forest with top 6 features: 96.6027%
Accuracy Random Forest with top 5 features: 97.2304%
Accuracy Random Forest with top 4 features: 96.9350%
Accuracy Random Forest with top 3 features: 95.9380%
Accuracy Random Forest with top 2 features: 86.5953%
Accuracy Random Forest with top 1 features: 78.7666%

Best Accuracy: 99.0768094534712
Best k: 17
Best Selected Feature Names: Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;nitrates&#39;, &#39;nitrites&#39;, &#39;mercury&#39;,
       &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;, &#39;silver&#39;, &#39;uranium&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="logistic-regression">
<h4>2. Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">joblib</span>

<span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_minmax</span><span class="p">)</span>

    <span class="c1"># Mendapatkan nama fitur terpilih</span>
    <span class="n">selected_feature_names</span> <span class="o">=</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="c1"># Membuat model Logistic Regression</span>
    <span class="n">lr_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">lr_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">y_pred_lr</span> <span class="o">=</span> <span class="n">lr_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model Logistic Regression</span>
    <span class="n">accuracy_lr</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lr</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy Logistic Regression with top </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> features: </span><span class="si">{</span><span class="n">accuracy_lr</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_lr</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_lr</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">selected_feature_names</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">lr_model</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Accuracy:&quot;</span><span class="p">,</span> <span class="n">best_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best k:&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Selected Feature Names:&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>

<span class="c1"># Menyimpan model yang telah dilatih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">lr_model</span><span class="p">,</span> <span class="s1">&#39;modellogisticregression.pkl&#39;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fiturlogisticregression.pkl&#39;</span><span class="p">)</span>

<span class="n">accuracy_logreg</span> <span class="o">=</span> <span class="n">best_accuracy</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy Logistic Regression with top 20 features: 79.8744%
Accuracy Logistic Regression with top 19 features: 79.9852%
Accuracy Logistic Regression with top 18 features: 79.3205%
Accuracy Logistic Regression with top 17 features: 78.7297%
Accuracy Logistic Regression with top 16 features: 78.6928%
Accuracy Logistic Regression with top 15 features: 78.9143%
Accuracy Logistic Regression with top 14 features: 78.8774%
Accuracy Logistic Regression with top 13 features: 78.8405%
Accuracy Logistic Regression with top 12 features: 78.2866%
Accuracy Logistic Regression with top 11 features: 78.5451%
Accuracy Logistic Regression with top 10 features: 79.3575%
Accuracy Logistic Regression with top 9 features: 77.6957%
Accuracy Logistic Regression with top 8 features: 77.3634%
Accuracy Logistic Regression with top 7 features: 77.5480%
Accuracy Logistic Regression with top 6 features: 78.3604%
Accuracy Logistic Regression with top 5 features: 77.4003%
Accuracy Logistic Regression with top 4 features: 77.1787%
Accuracy Logistic Regression with top 3 features: 77.3264%
Accuracy Logistic Regression with top 2 features: 76.7725%
Accuracy Logistic Regression with top 1 features: 71.5657%

Best Accuracy: 79.98522895125554
Best k: 19
Best Selected Feature Names: Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;lead&#39;, &#39;nitrates&#39;,
       &#39;nitrites&#39;, &#39;mercury&#39;, &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;, &#39;silver&#39;,
       &#39;uranium&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="svm">
<h4>3. SVM<a class="headerlink" href="#svm" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">joblib</span>

<span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_minmax</span><span class="p">)</span>

    <span class="c1"># Mendapatkan nama fitur terpilih</span>
    <span class="n">selected_feature_names</span> <span class="o">=</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="c1"># Membuat model Support Vector Machine (SVM)</span>
    <span class="n">svm_model</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">svm_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">y_pred_svm</span> <span class="o">=</span> <span class="n">svm_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model SVM</span>
    <span class="n">accuracy_svm</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_svm</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy SVM with top </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> features: </span><span class="si">{</span><span class="n">accuracy_svm</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_svm</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_svm</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">selected_feature_names</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">svm_model</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Accuracy:&quot;</span><span class="p">,</span> <span class="n">best_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best k:&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Selected Feature Names:&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>

<span class="c1"># Menyimpan model yang telah dilatih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">svm_model</span><span class="p">,</span> <span class="s1">&#39;modelsvm.pkl&#39;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fitursvm.pkl&#39;</span><span class="p">)</span>

<span class="n">accuracy_svm</span> <span class="o">=</span> <span class="n">best_accuracy</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy SVM with top 20 features: 93.9808%
Accuracy SVM with top 19 features: 93.6115%
Accuracy SVM with top 18 features: 93.6484%
Accuracy SVM with top 17 features: 93.3530%
Accuracy SVM with top 16 features: 92.0975%
Accuracy SVM with top 15 features: 91.6544%
Accuracy SVM with top 14 features: 91.7282%
Accuracy SVM with top 13 features: 91.9129%
Accuracy SVM with top 12 features: 88.8479%
Accuracy SVM with top 11 features: 87.9616%
Accuracy SVM with top 10 features: 87.1492%
Accuracy SVM with top 9 features: 85.3028%
Accuracy SVM with top 8 features: 85.4874%
Accuracy SVM with top 7 features: 84.6012%
Accuracy SVM with top 6 features: 84.7489%
Accuracy SVM with top 5 features: 80.6130%
Accuracy SVM with top 4 features: 79.9114%
Accuracy SVM with top 3 features: 79.3205%
Accuracy SVM with top 2 features: 79.3944%
Accuracy SVM with top 1 features: 75.5170%

Best Accuracy: 93.98079763663219
Best k: 20
Best Selected Feature Names: Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;flouride&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;lead&#39;,
       &#39;nitrates&#39;, &#39;nitrites&#39;, &#39;mercury&#39;, &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;,
       &#39;silver&#39;, &#39;uranium&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="naive-bayes">
<h4>4. Naive Bayes<a class="headerlink" href="#naive-bayes" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">joblib</span>

<span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_minmax</span><span class="p">)</span>

    <span class="c1"># Mendapatkan nama fitur terpilih</span>
    <span class="n">selected_feature_names</span> <span class="o">=</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="c1"># Membuat model Naive Bayes (Multinomial)</span>
    <span class="n">nb_model</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>

    <span class="c1"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">nb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">y_pred_nb</span> <span class="o">=</span> <span class="n">nb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model Naive Bayes</span>
    <span class="n">accuracy_nb</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_nb</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy Naive Bayes with top </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> features: </span><span class="si">{</span><span class="n">accuracy_nb</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_nb</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_nb</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">selected_feature_names</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">nb_model</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Accuracy:&quot;</span><span class="p">,</span> <span class="n">best_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best k:&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Selected Feature Names:&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>

<span class="c1"># Menyimpan model yang telah dilatih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">nb_model</span><span class="p">,</span> <span class="s1">&#39;modelnaivebayes.pkl&#39;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fiturnaivebayes.pkl&#39;</span><span class="p">)</span>

<span class="n">accuracy_nb</span> <span class="o">=</span> <span class="n">best_accuracy</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy Naive Bayes with top 20 features: 76.1817%
Accuracy Naive Bayes with top 19 features: 76.1817%
Accuracy Naive Bayes with top 18 features: 76.0340%
Accuracy Naive Bayes with top 17 features: 76.0340%
Accuracy Naive Bayes with top 16 features: 76.3294%
Accuracy Naive Bayes with top 15 features: 76.8464%
Accuracy Naive Bayes with top 14 features: 76.8464%
Accuracy Naive Bayes with top 13 features: 77.0310%
Accuracy Naive Bayes with top 12 features: 77.0310%
Accuracy Naive Bayes with top 11 features: 77.3264%
Accuracy Naive Bayes with top 10 features: 77.2895%
Accuracy Naive Bayes with top 9 features: 76.8095%
Accuracy Naive Bayes with top 8 features: 76.9202%
Accuracy Naive Bayes with top 7 features: 76.9941%
Accuracy Naive Bayes with top 6 features: 77.4372%
Accuracy Naive Bayes with top 5 features: 77.5480%
Accuracy Naive Bayes with top 4 features: 75.5908%
Accuracy Naive Bayes with top 3 features: 75.7016%
Accuracy Naive Bayes with top 2 features: 76.5510%
Accuracy Naive Bayes with top 1 features: 49.1876%

Best Accuracy: 77.5480059084195
Best k: 5
Best Selected Feature Names: Index([&#39;aluminium&#39;, &#39;arsenic&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;, &#39;chromium&#39;], dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="adaboost">
<h4>5. Adaboost<a class="headerlink" href="#adaboost" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">joblib</span>

<span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_minmax</span><span class="p">)</span>

    <span class="c1"># Mendapatkan nama fitur terpilih</span>
    <span class="n">selected_feature_names</span> <span class="o">=</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="c1"># Membuat model Adaboost</span>
    <span class="n">adaboost_model</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">adaboost_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">y_pred_adaboost</span> <span class="o">=</span> <span class="n">adaboost_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model Adaboost</span>
    <span class="n">accuracy_adaboost</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_adaboost</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy Adaboost with top </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> features: </span><span class="si">{</span><span class="n">accuracy_adaboost</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_adaboost</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_adaboost</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">selected_feature_names</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">adaboost_model</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Accuracy:&quot;</span><span class="p">,</span> <span class="n">best_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best k:&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Selected Feature Names:&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>

<span class="c1"># Menyimpan model yang telah dilatih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">adaboost_model</span><span class="p">,</span> <span class="s1">&#39;modeladaboost.pkl&#39;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fituradaboost.pkl&#39;</span><span class="p">)</span>

<span class="n">accuracy_adaboost</span> <span class="o">=</span> <span class="n">best_accuracy</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy Adaboost with top 20 features: 88.4417%
Accuracy Adaboost with top 19 features: 88.4417%
Accuracy Adaboost with top 18 features: 89.1433%
Accuracy Adaboost with top 17 features: 87.0753%
Accuracy Adaboost with top 16 features: 86.2999%
Accuracy Adaboost with top 15 features: 86.8168%
Accuracy Adaboost with top 14 features: 86.5583%
Accuracy Adaboost with top 13 features: 87.3708%
Accuracy Adaboost with top 12 features: 85.8567%
Accuracy Adaboost with top 11 features: 84.7858%
Accuracy Adaboost with top 10 features: 85.0074%
Accuracy Adaboost with top 9 features: 85.2290%
Accuracy Adaboost with top 8 features: 84.6750%
Accuracy Adaboost with top 7 features: 84.1211%
Accuracy Adaboost with top 6 features: 83.9734%
Accuracy Adaboost with top 5 features: 79.0620%
Accuracy Adaboost with top 4 features: 77.5849%
Accuracy Adaboost with top 3 features: 77.4372%
Accuracy Adaboost with top 2 features: 76.1817%
Accuracy Adaboost with top 1 features: 77.0679%

Best Accuracy: 89.14327917282127
Best k: 18
Best Selected Feature Names: Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;nitrates&#39;, &#39;nitrites&#39;,
       &#39;mercury&#39;, &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;, &#39;silver&#39;, &#39;uranium&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="gradient-boosting">
<h4>6. Gradient Boosting<a class="headerlink" href="#gradient-boosting" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">joblib</span>

<span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_minmax</span><span class="p">)</span>

    <span class="c1"># Mendapatkan nama fitur terpilih</span>
    <span class="n">selected_feature_names</span> <span class="o">=</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="c1"># Membuat model Gradient Boosting</span>
    <span class="n">gb_model</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">gb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">y_pred_gb</span> <span class="o">=</span> <span class="n">gb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model Gradient Boosting</span>
    <span class="n">accuracy_gb</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_gb</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy Gradient Boosting with top </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> features: </span><span class="si">{</span><span class="n">accuracy_gb</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_gb</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_gb</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">selected_feature_names</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">gb_model</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Accuracy:&quot;</span><span class="p">,</span> <span class="n">best_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best k:&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Selected Feature Names:&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>

<span class="c1"># Menyimpan model yang telah dilatih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">gb_model</span><span class="p">,</span> <span class="s1">&#39;modelgradientboosting.pkl&#39;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fiturgradientboosting.pkl&#39;</span><span class="p">)</span>

<span class="n">accuracy_gb</span> <span class="o">=</span> <span class="n">best_accuracy</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy Gradient Boosting with top 20 features: 95.7533%
Accuracy Gradient Boosting with top 19 features: 95.7164%
Accuracy Gradient Boosting with top 18 features: 95.7533%
Accuracy Gradient Boosting with top 17 features: 95.5318%
Accuracy Gradient Boosting with top 16 features: 95.0148%
Accuracy Gradient Boosting with top 15 features: 94.3870%
Accuracy Gradient Boosting with top 14 features: 94.3870%
Accuracy Gradient Boosting with top 13 features: 94.2393%
Accuracy Gradient Boosting with top 12 features: 92.2821%
Accuracy Gradient Boosting with top 11 features: 91.3589%
Accuracy Gradient Boosting with top 10 features: 90.7312%
Accuracy Gradient Boosting with top 9 features: 89.2541%
Accuracy Gradient Boosting with top 8 features: 88.5155%
Accuracy Gradient Boosting with top 7 features: 88.3309%
Accuracy Gradient Boosting with top 6 features: 86.4845%
Accuracy Gradient Boosting with top 5 features: 82.2378%
Accuracy Gradient Boosting with top 4 features: 81.9055%
Accuracy Gradient Boosting with top 3 features: 81.9055%
Accuracy Gradient Boosting with top 2 features: 81.5731%
Accuracy Gradient Boosting with top 1 features: 77.6588%

Best Accuracy: 95.7533234859675
Best k: 20
Best Selected Feature Names: Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;flouride&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;lead&#39;,
       &#39;nitrates&#39;, &#39;nitrites&#39;, &#39;mercury&#39;, &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;,
       &#39;silver&#39;, &#39;uranium&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="neural-network">
<h4>7. Neural Network<a class="headerlink" href="#neural-network" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">joblib</span>

<span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_minmax</span><span class="p">)</span>

    <span class="c1"># Mendapatkan nama fitur terpilih</span>
    <span class="n">selected_feature_names</span> <span class="o">=</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="c1"># Membuat model Neural Network (MLP)</span>
    <span class="n">mlp_model</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,),</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">mlp_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">y_pred_mlp</span> <span class="o">=</span> <span class="n">mlp_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model Neural Network (MLP)</span>
    <span class="n">accuracy_mlp</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_mlp</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy MLP with top </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> features: </span><span class="si">{</span><span class="n">accuracy_mlp</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_mlp</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_mlp</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">selected_feature_names</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">mlp_model</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Accuracy:&quot;</span><span class="p">,</span> <span class="n">best_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best k:&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Selected Feature Names:&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>

<span class="c1"># Menyimpan model yang telah dilatih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">mlp_model</span><span class="p">,</span> <span class="s1">&#39;modelneuralnetwork.pkl&#39;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fiturneuralnetwork.pkl&#39;</span><span class="p">)</span>

<span class="n">accuracy_nn</span> <span class="o">=</span> <span class="n">best_accuracy</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy MLP with top 20 features: 97.4151%
Accuracy MLP with top 19 features: 97.5628%
Accuracy MLP with top 18 features: 97.6736%
Accuracy MLP with top 17 features: 97.3781%
Accuracy MLP with top 16 features: 96.0857%
Accuracy MLP with top 15 features: 95.2733%
Accuracy MLP with top 14 features: 94.9778%
Accuracy MLP with top 13 features: 94.7194%
Accuracy MLP with top 12 features: 91.0266%
Accuracy MLP with top 11 features: 89.7710%
Accuracy MLP with top 10 features: 89.1064%
Accuracy MLP with top 9 features: 87.1492%
Accuracy MLP with top 8 features: 86.4476%
Accuracy MLP with top 7 features: 85.1920%
Accuracy MLP with top 6 features: 85.3767%
Accuracy MLP with top 5 features: 80.3176%
Accuracy MLP with top 4 features: 79.7637%
Accuracy MLP with top 3 features: 79.3575%
Accuracy MLP with top 2 features: 79.1728%
Accuracy MLP with top 1 features: 76.5140%

Best Accuracy: 97.67355982274741
Best k: 18
Best Selected Feature Names: Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;nitrates&#39;, &#39;nitrites&#39;,
       &#39;mercury&#39;, &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;, &#39;silver&#39;, &#39;uranium&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="decission-tree">
<h4>8. Decission Tree<a class="headerlink" href="#decission-tree" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">joblib</span>

<span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_minmax</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_minmax</span><span class="p">)</span>

    <span class="c1"># Mendapatkan nama fitur terpilih</span>
    <span class="n">selected_feature_names</span> <span class="o">=</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="c1"># Membuat model Decision Tree</span>
    <span class="n">dt_model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">dt_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">y_pred_dt</span> <span class="o">=</span> <span class="n">dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model Decision Tree</span>
    <span class="n">accuracy_dt</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy Decision Tree with top </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> features: </span><span class="si">{</span><span class="n">accuracy_dt</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_dt</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_dt</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">selected_feature_names</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">dt_model</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Accuracy:&quot;</span><span class="p">,</span> <span class="n">best_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best k:&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Selected Feature Names:&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>

<span class="c1"># Menyimpan model yang telah dilatih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">dt_model</span><span class="p">,</span> <span class="s1">&#39;modeldecisiontree.pkl&#39;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fiturdecisiontree.pkl&#39;</span><span class="p">)</span>

<span class="n">accuracy_dt</span> <span class="o">=</span> <span class="n">best_accuracy</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy Decision Tree with top 20 features: 98.4490%
Accuracy Decision Tree with top 19 features: 98.6337%
Accuracy Decision Tree with top 18 features: 98.7075%
Accuracy Decision Tree with top 17 features: 98.5598%
Accuracy Decision Tree with top 16 features: 98.1905%
Accuracy Decision Tree with top 15 features: 97.9690%
Accuracy Decision Tree with top 14 features: 97.7474%
Accuracy Decision Tree with top 13 features: 97.7474%
Accuracy Decision Tree with top 12 features: 97.6366%
Accuracy Decision Tree with top 11 features: 97.3412%
Accuracy Decision Tree with top 10 features: 97.5628%
Accuracy Decision Tree with top 9 features: 97.0827%
Accuracy Decision Tree with top 8 features: 96.6396%
Accuracy Decision Tree with top 7 features: 96.2334%
Accuracy Decision Tree with top 6 features: 95.9749%
Accuracy Decision Tree with top 5 features: 95.5687%
Accuracy Decision Tree with top 4 features: 95.5318%
Accuracy Decision Tree with top 3 features: 94.9040%
Accuracy Decision Tree with top 2 features: 86.3737%
Accuracy Decision Tree with top 1 features: 78.5451%

Best Accuracy: 98.70753323485968
Best k: 18
Best Selected Feature Names: Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;nitrates&#39;, &#39;nitrites&#39;,
       &#39;mercury&#39;, &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;, &#39;silver&#39;, &#39;uranium&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="pycaret">
<h4>9. Pycaret<a class="headerlink" href="#pycaret" title="Permalink to this heading">#</a></h4>
<center>--------PYCARET--------</center><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">datapycaret</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data_balancing.xlsx&#39;</span><span class="p">)</span>
<span class="n">datapycaret</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aluminium</th>
      <th>ammonia</th>
      <th>arsenic</th>
      <th>barium</th>
      <th>cadmium</th>
      <th>chloramine</th>
      <th>chromium</th>
      <th>copper</th>
      <th>flouride</th>
      <th>bacteria</th>
      <th>...</th>
      <th>lead</th>
      <th>nitrates</th>
      <th>nitrites</th>
      <th>mercury</th>
      <th>perchlorate</th>
      <th>radium</th>
      <th>selenium</th>
      <th>silver</th>
      <th>uranium</th>
      <th>is_safe</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.65</td>
      <td>9.08</td>
      <td>0.04</td>
      <td>2.85</td>
      <td>0.007</td>
      <td>0.35</td>
      <td>0.83</td>
      <td>0.17</td>
      <td>0.05</td>
      <td>0.20</td>
      <td>...</td>
      <td>0.054</td>
      <td>16.08</td>
      <td>1.13</td>
      <td>0.007</td>
      <td>37.75</td>
      <td>6.78</td>
      <td>0.08</td>
      <td>0.34</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.32</td>
      <td>21.16</td>
      <td>0.01</td>
      <td>3.31</td>
      <td>0.002</td>
      <td>5.28</td>
      <td>0.68</td>
      <td>0.66</td>
      <td>0.90</td>
      <td>0.65</td>
      <td>...</td>
      <td>0.100</td>
      <td>2.01</td>
      <td>1.93</td>
      <td>0.003</td>
      <td>32.26</td>
      <td>3.21</td>
      <td>0.08</td>
      <td>0.27</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.01</td>
      <td>14.02</td>
      <td>0.04</td>
      <td>0.58</td>
      <td>0.008</td>
      <td>4.24</td>
      <td>0.53</td>
      <td>0.02</td>
      <td>0.99</td>
      <td>0.05</td>
      <td>...</td>
      <td>0.078</td>
      <td>14.16</td>
      <td>1.11</td>
      <td>0.006</td>
      <td>50.28</td>
      <td>7.07</td>
      <td>0.07</td>
      <td>0.44</td>
      <td>0.01</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.36</td>
      <td>11.33</td>
      <td>0.04</td>
      <td>2.96</td>
      <td>0.001</td>
      <td>7.23</td>
      <td>0.03</td>
      <td>1.66</td>
      <td>1.08</td>
      <td>0.71</td>
      <td>...</td>
      <td>0.016</td>
      <td>1.41</td>
      <td>1.29</td>
      <td>0.004</td>
      <td>9.12</td>
      <td>1.72</td>
      <td>0.02</td>
      <td>0.45</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.92</td>
      <td>24.33</td>
      <td>0.03</td>
      <td>0.20</td>
      <td>0.006</td>
      <td>2.67</td>
      <td>0.69</td>
      <td>0.57</td>
      <td>0.61</td>
      <td>0.13</td>
      <td>...</td>
      <td>0.117</td>
      <td>6.74</td>
      <td>1.11</td>
      <td>0.003</td>
      <td>16.90</td>
      <td>2.41</td>
      <td>0.02</td>
      <td>0.06</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 21 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pycaret.classification</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pycaret.classification</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Inisialisasi pycaret</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">datapycaret</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="n">session_id</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

<span class="c1"># Bandingkan beberapa model</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">compare_models</span><span class="p">(</span><span class="n">fold</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Membuat model terpilih (tanpa tuning)</span>
<span class="n">selected_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">best_model</span><span class="p">)</span>

<span class="c1"># Melakukan seleksi fitur menggunakan SelectKBest</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">(</span><span class="s1">&#39;X_train&#39;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">(</span><span class="s1">&#39;X_test&#39;</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">(</span><span class="s1">&#39;y_train&#39;</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">(</span><span class="s1">&#39;y_test&#39;</span><span class="p">)</span>

<span class="n">minmax_scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X_train_minmax</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_minmax</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="c1"># Membuat model terpilih</span>
    <span class="n">selected_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah terpilih fiturnya</span>
    <span class="n">y_pred_selected</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model terpilih</span>
    <span class="n">accuracy_selected</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_selected</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy with top </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> features: </span><span class="si">{</span><span class="n">accuracy_selected</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_selected</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_selected</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">selected_model</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Accuracy:&quot;</span><span class="p">,</span> <span class="n">best_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best k:&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Selected Feature Names:&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>

<span class="c1"># Menyimpan model yang telah dilatih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;modelpycaret.pkl&#39;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fiturpycaret.pkl&#39;</span><span class="p">)</span>

<span class="n">accuracy_pycr</span> <span class="o">=</span> <span class="n">best_accuracy</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style type="text/css">
#T_bf267_row8_col1 {
  background-color: lightgreen;
}
</style>
<table id="T_bf267">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_bf267_level0_col0" class="col_heading level0 col0" >Description</th>
      <th id="T_bf267_level0_col1" class="col_heading level0 col1" >Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_bf267_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_bf267_row0_col0" class="data row0 col0" >Session id</td>
      <td id="T_bf267_row0_col1" class="data row0 col1" >123</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_bf267_row1_col0" class="data row1 col0" >Target</td>
      <td id="T_bf267_row1_col1" class="data row1 col1" >is_safe</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_bf267_row2_col0" class="data row2 col0" >Target type</td>
      <td id="T_bf267_row2_col1" class="data row2 col1" >Binary</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_bf267_row3_col0" class="data row3 col0" >Original data shape</td>
      <td id="T_bf267_row3_col1" class="data row3 col1" >(13538, 21)</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_bf267_row4_col0" class="data row4 col0" >Transformed data shape</td>
      <td id="T_bf267_row4_col1" class="data row4 col1" >(13538, 21)</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_bf267_row5_col0" class="data row5 col0" >Transformed train set shape</td>
      <td id="T_bf267_row5_col1" class="data row5 col1" >(9476, 21)</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_bf267_row6_col0" class="data row6 col0" >Transformed test set shape</td>
      <td id="T_bf267_row6_col1" class="data row6 col1" >(4062, 21)</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_bf267_row7_col0" class="data row7 col0" >Numeric features</td>
      <td id="T_bf267_row7_col1" class="data row7 col1" >20</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_bf267_row8_col0" class="data row8 col0" >Preprocess</td>
      <td id="T_bf267_row8_col1" class="data row8 col1" >True</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_bf267_row9_col0" class="data row9 col0" >Imputation type</td>
      <td id="T_bf267_row9_col1" class="data row9 col1" >simple</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row10" class="row_heading level0 row10" >10</th>
      <td id="T_bf267_row10_col0" class="data row10 col0" >Numeric imputation</td>
      <td id="T_bf267_row10_col1" class="data row10 col1" >mean</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row11" class="row_heading level0 row11" >11</th>
      <td id="T_bf267_row11_col0" class="data row11 col0" >Categorical imputation</td>
      <td id="T_bf267_row11_col1" class="data row11 col1" >mode</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row12" class="row_heading level0 row12" >12</th>
      <td id="T_bf267_row12_col0" class="data row12 col0" >Fold Generator</td>
      <td id="T_bf267_row12_col1" class="data row12 col1" >StratifiedKFold</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row13" class="row_heading level0 row13" >13</th>
      <td id="T_bf267_row13_col0" class="data row13 col0" >Fold Number</td>
      <td id="T_bf267_row13_col1" class="data row13 col1" >10</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row14" class="row_heading level0 row14" >14</th>
      <td id="T_bf267_row14_col0" class="data row14 col0" >CPU Jobs</td>
      <td id="T_bf267_row14_col1" class="data row14 col1" >-1</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row15" class="row_heading level0 row15" >15</th>
      <td id="T_bf267_row15_col0" class="data row15 col0" >Use GPU</td>
      <td id="T_bf267_row15_col1" class="data row15 col1" >False</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row16" class="row_heading level0 row16" >16</th>
      <td id="T_bf267_row16_col0" class="data row16 col0" >Log Experiment</td>
      <td id="T_bf267_row16_col1" class="data row16 col1" >False</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row17" class="row_heading level0 row17" >17</th>
      <td id="T_bf267_row17_col0" class="data row17 col0" >Experiment Name</td>
      <td id="T_bf267_row17_col1" class="data row17 col1" >clf-default-name</td>
    </tr>
    <tr>
      <th id="T_bf267_level0_row18" class="row_heading level0 row18" >18</th>
      <td id="T_bf267_row18_col0" class="data row18 col0" >USI</td>
      <td id="T_bf267_row18_col1" class="data row18 col1" >9a67</td>
    </tr>
  </tbody>
</table>
</div><div class="output text_html"></div><div class="output text_html"><style type="text/css">
#T_e17a5 th {
  text-align: left;
}
#T_e17a5_row0_col0, #T_e17a5_row0_col2, #T_e17a5_row0_col3, #T_e17a5_row1_col0, #T_e17a5_row1_col1, #T_e17a5_row1_col3, #T_e17a5_row1_col4, #T_e17a5_row1_col5, #T_e17a5_row1_col6, #T_e17a5_row1_col7, #T_e17a5_row2_col0, #T_e17a5_row2_col1, #T_e17a5_row2_col2, #T_e17a5_row2_col3, #T_e17a5_row2_col4, #T_e17a5_row2_col5, #T_e17a5_row2_col6, #T_e17a5_row2_col7, #T_e17a5_row3_col0, #T_e17a5_row3_col1, #T_e17a5_row3_col2, #T_e17a5_row3_col4, #T_e17a5_row3_col5, #T_e17a5_row3_col6, #T_e17a5_row3_col7, #T_e17a5_row4_col0, #T_e17a5_row4_col1, #T_e17a5_row4_col2, #T_e17a5_row4_col3, #T_e17a5_row4_col4, #T_e17a5_row4_col5, #T_e17a5_row4_col6, #T_e17a5_row4_col7, #T_e17a5_row5_col0, #T_e17a5_row5_col1, #T_e17a5_row5_col2, #T_e17a5_row5_col3, #T_e17a5_row5_col4, #T_e17a5_row5_col5, #T_e17a5_row5_col6, #T_e17a5_row5_col7, #T_e17a5_row6_col0, #T_e17a5_row6_col1, #T_e17a5_row6_col2, #T_e17a5_row6_col3, #T_e17a5_row6_col4, #T_e17a5_row6_col5, #T_e17a5_row6_col6, #T_e17a5_row6_col7, #T_e17a5_row7_col0, #T_e17a5_row7_col1, #T_e17a5_row7_col2, #T_e17a5_row7_col3, #T_e17a5_row7_col4, #T_e17a5_row7_col5, #T_e17a5_row7_col6, #T_e17a5_row7_col7, #T_e17a5_row8_col0, #T_e17a5_row8_col1, #T_e17a5_row8_col2, #T_e17a5_row8_col3, #T_e17a5_row8_col4, #T_e17a5_row8_col5, #T_e17a5_row8_col6, #T_e17a5_row8_col7, #T_e17a5_row9_col0, #T_e17a5_row9_col1, #T_e17a5_row9_col2, #T_e17a5_row9_col3, #T_e17a5_row9_col4, #T_e17a5_row9_col5, #T_e17a5_row9_col6, #T_e17a5_row9_col7, #T_e17a5_row10_col0, #T_e17a5_row10_col1, #T_e17a5_row10_col2, #T_e17a5_row10_col3, #T_e17a5_row10_col4, #T_e17a5_row10_col5, #T_e17a5_row10_col6, #T_e17a5_row10_col7, #T_e17a5_row11_col0, #T_e17a5_row11_col1, #T_e17a5_row11_col2, #T_e17a5_row11_col3, #T_e17a5_row11_col4, #T_e17a5_row11_col5, #T_e17a5_row11_col6, #T_e17a5_row11_col7, #T_e17a5_row12_col0, #T_e17a5_row12_col1, #T_e17a5_row12_col2, #T_e17a5_row12_col3, #T_e17a5_row12_col4, #T_e17a5_row12_col5, #T_e17a5_row12_col6, #T_e17a5_row12_col7, #T_e17a5_row13_col0, #T_e17a5_row13_col1, #T_e17a5_row13_col2, #T_e17a5_row13_col3, #T_e17a5_row13_col4, #T_e17a5_row13_col5, #T_e17a5_row13_col6, #T_e17a5_row13_col7 {
  text-align: left;
}
#T_e17a5_row0_col1, #T_e17a5_row0_col4, #T_e17a5_row0_col5, #T_e17a5_row0_col6, #T_e17a5_row0_col7, #T_e17a5_row1_col2, #T_e17a5_row3_col3 {
  text-align: left;
  background-color: yellow;
}
#T_e17a5_row0_col8, #T_e17a5_row1_col8, #T_e17a5_row2_col8, #T_e17a5_row3_col8, #T_e17a5_row4_col8, #T_e17a5_row5_col8, #T_e17a5_row6_col8, #T_e17a5_row7_col8, #T_e17a5_row8_col8, #T_e17a5_row9_col8, #T_e17a5_row10_col8, #T_e17a5_row11_col8, #T_e17a5_row12_col8 {
  text-align: left;
  background-color: lightgrey;
}
#T_e17a5_row13_col8 {
  text-align: left;
  background-color: yellow;
  background-color: lightgrey;
}
</style>
<table id="T_e17a5">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_e17a5_level0_col0" class="col_heading level0 col0" >Model</th>
      <th id="T_e17a5_level0_col1" class="col_heading level0 col1" >Accuracy</th>
      <th id="T_e17a5_level0_col2" class="col_heading level0 col2" >AUC</th>
      <th id="T_e17a5_level0_col3" class="col_heading level0 col3" >Recall</th>
      <th id="T_e17a5_level0_col4" class="col_heading level0 col4" >Prec.</th>
      <th id="T_e17a5_level0_col5" class="col_heading level0 col5" >F1</th>
      <th id="T_e17a5_level0_col6" class="col_heading level0 col6" >Kappa</th>
      <th id="T_e17a5_level0_col7" class="col_heading level0 col7" >MCC</th>
      <th id="T_e17a5_level0_col8" class="col_heading level0 col8" >TT (Sec)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_e17a5_level0_row0" class="row_heading level0 row0" >et</th>
      <td id="T_e17a5_row0_col0" class="data row0 col0" >Extra Trees Classifier</td>
      <td id="T_e17a5_row0_col1" class="data row0 col1" >0.9884</td>
      <td id="T_e17a5_row0_col2" class="data row0 col2" >0.9997</td>
      <td id="T_e17a5_row0_col3" class="data row0 col3" >0.9970</td>
      <td id="T_e17a5_row0_col4" class="data row0 col4" >0.9801</td>
      <td id="T_e17a5_row0_col5" class="data row0 col5" >0.9885</td>
      <td id="T_e17a5_row0_col6" class="data row0 col6" >0.9768</td>
      <td id="T_e17a5_row0_col7" class="data row0 col7" >0.9769</td>
      <td id="T_e17a5_row0_col8" class="data row0 col8" >1.5720</td>
    </tr>
    <tr>
      <th id="T_e17a5_level0_row1" class="row_heading level0 row1" >rf</th>
      <td id="T_e17a5_row1_col0" class="data row1 col0" >Random Forest Classifier</td>
      <td id="T_e17a5_row1_col1" class="data row1 col1" >0.9840</td>
      <td id="T_e17a5_row1_col2" class="data row1 col2" >0.9998</td>
      <td id="T_e17a5_row1_col3" class="data row1 col3" >0.9992</td>
      <td id="T_e17a5_row1_col4" class="data row1 col4" >0.9697</td>
      <td id="T_e17a5_row1_col5" class="data row1 col5" >0.9842</td>
      <td id="T_e17a5_row1_col6" class="data row1 col6" >0.9679</td>
      <td id="T_e17a5_row1_col7" class="data row1 col7" >0.9684</td>
      <td id="T_e17a5_row1_col8" class="data row1 col8" >3.3060</td>
    </tr>
    <tr>
      <th id="T_e17a5_level0_row2" class="row_heading level0 row2" >lightgbm</th>
      <td id="T_e17a5_row2_col0" class="data row2 col0" >Light Gradient Boosting Machine</td>
      <td id="T_e17a5_row2_col1" class="data row2 col1" >0.9826</td>
      <td id="T_e17a5_row2_col2" class="data row2 col2" >0.9990</td>
      <td id="T_e17a5_row2_col3" class="data row2 col3" >0.9989</td>
      <td id="T_e17a5_row2_col4" class="data row2 col4" >0.9673</td>
      <td id="T_e17a5_row2_col5" class="data row2 col5" >0.9829</td>
      <td id="T_e17a5_row2_col6" class="data row2 col6" >0.9652</td>
      <td id="T_e17a5_row2_col7" class="data row2 col7" >0.9657</td>
      <td id="T_e17a5_row2_col8" class="data row2 col8" >0.7060</td>
    </tr>
    <tr>
      <th id="T_e17a5_level0_row3" class="row_heading level0 row3" >dt</th>
      <td id="T_e17a5_row3_col0" class="data row3 col0" >Decision Tree Classifier</td>
      <td id="T_e17a5_row3_col1" class="data row3 col1" >0.9825</td>
      <td id="T_e17a5_row3_col2" class="data row3 col2" >0.9825</td>
      <td id="T_e17a5_row3_col3" class="data row3 col3" >0.9996</td>
      <td id="T_e17a5_row3_col4" class="data row3 col4" >0.9666</td>
      <td id="T_e17a5_row3_col5" class="data row3 col5" >0.9828</td>
      <td id="T_e17a5_row3_col6" class="data row3 col6" >0.9650</td>
      <td id="T_e17a5_row3_col7" class="data row3 col7" >0.9655</td>
      <td id="T_e17a5_row3_col8" class="data row3 col8" >0.1820</td>
    </tr>
    <tr>
      <th id="T_e17a5_level0_row4" class="row_heading level0 row4" >gbc</th>
      <td id="T_e17a5_row4_col0" class="data row4 col0" >Gradient Boosting Classifier</td>
      <td id="T_e17a5_row4_col1" class="data row4 col1" >0.9545</td>
      <td id="T_e17a5_row4_col2" class="data row4 col2" >0.9894</td>
      <td id="T_e17a5_row4_col3" class="data row4 col3" >0.9812</td>
      <td id="T_e17a5_row4_col4" class="data row4 col4" >0.9316</td>
      <td id="T_e17a5_row4_col5" class="data row4 col5" >0.9557</td>
      <td id="T_e17a5_row4_col6" class="data row4 col6" >0.9090</td>
      <td id="T_e17a5_row4_col7" class="data row4 col7" >0.9104</td>
      <td id="T_e17a5_row4_col8" class="data row4 col8" >4.4280</td>
    </tr>
    <tr>
      <th id="T_e17a5_level0_row5" class="row_heading level0 row5" >ada</th>
      <td id="T_e17a5_row5_col0" class="data row5 col0" >Ada Boost Classifier</td>
      <td id="T_e17a5_row5_col1" class="data row5 col1" >0.8701</td>
      <td id="T_e17a5_row5_col2" class="data row5 col2" >0.9483</td>
      <td id="T_e17a5_row5_col3" class="data row5 col3" >0.8535</td>
      <td id="T_e17a5_row5_col4" class="data row5 col4" >0.8828</td>
      <td id="T_e17a5_row5_col5" class="data row5 col5" >0.8679</td>
      <td id="T_e17a5_row5_col6" class="data row5 col6" >0.7402</td>
      <td id="T_e17a5_row5_col7" class="data row5 col7" >0.7406</td>
      <td id="T_e17a5_row5_col8" class="data row5 col8" >1.3000</td>
    </tr>
    <tr>
      <th id="T_e17a5_level0_row6" class="row_heading level0 row6" >knn</th>
      <td id="T_e17a5_row6_col0" class="data row6 col0" >K Neighbors Classifier</td>
      <td id="T_e17a5_row6_col1" class="data row6 col1" >0.8351</td>
      <td id="T_e17a5_row6_col2" class="data row6 col2" >0.9050</td>
      <td id="T_e17a5_row6_col3" class="data row6 col3" >0.9491</td>
      <td id="T_e17a5_row6_col4" class="data row6 col4" >0.7729</td>
      <td id="T_e17a5_row6_col5" class="data row6 col5" >0.8519</td>
      <td id="T_e17a5_row6_col6" class="data row6 col6" >0.6701</td>
      <td id="T_e17a5_row6_col7" class="data row6 col7" >0.6885</td>
      <td id="T_e17a5_row6_col8" class="data row6 col8" >0.7660</td>
    </tr>
    <tr>
      <th id="T_e17a5_level0_row7" class="row_heading level0 row7" >qda</th>
      <td id="T_e17a5_row7_col0" class="data row7 col0" >Quadratic Discriminant Analysis</td>
      <td id="T_e17a5_row7_col1" class="data row7 col1" >0.8257</td>
      <td id="T_e17a5_row7_col2" class="data row7 col2" >0.9037</td>
      <td id="T_e17a5_row7_col3" class="data row7 col3" >0.8520</td>
      <td id="T_e17a5_row7_col4" class="data row7 col4" >0.8093</td>
      <td id="T_e17a5_row7_col5" class="data row7 col5" >0.8301</td>
      <td id="T_e17a5_row7_col6" class="data row7 col6" >0.6513</td>
      <td id="T_e17a5_row7_col7" class="data row7 col7" >0.6523</td>
      <td id="T_e17a5_row7_col8" class="data row7 col8" >0.1300</td>
    </tr>
    <tr>
      <th id="T_e17a5_level0_row8" class="row_heading level0 row8" >lda</th>
      <td id="T_e17a5_row8_col0" class="data row8 col0" >Linear Discriminant Analysis</td>
      <td id="T_e17a5_row8_col1" class="data row8 col1" >0.7863</td>
      <td id="T_e17a5_row8_col2" class="data row8 col2" >0.8673</td>
      <td id="T_e17a5_row8_col3" class="data row8 col3" >0.7598</td>
      <td id="T_e17a5_row8_col4" class="data row8 col4" >0.8023</td>
      <td id="T_e17a5_row8_col5" class="data row8 col5" >0.7805</td>
      <td id="T_e17a5_row8_col6" class="data row8 col6" >0.5726</td>
      <td id="T_e17a5_row8_col7" class="data row8 col7" >0.5735</td>
      <td id="T_e17a5_row8_col8" class="data row8 col8" >0.1360</td>
    </tr>
    <tr>
      <th id="T_e17a5_level0_row9" class="row_heading level0 row9" >ridge</th>
      <td id="T_e17a5_row9_col0" class="data row9 col0" >Ridge Classifier</td>
      <td id="T_e17a5_row9_col1" class="data row9 col1" >0.7846</td>
      <td id="T_e17a5_row9_col2" class="data row9 col2" >0.0000</td>
      <td id="T_e17a5_row9_col3" class="data row9 col3" >0.7497</td>
      <td id="T_e17a5_row9_col4" class="data row9 col4" >0.8060</td>
      <td id="T_e17a5_row9_col5" class="data row9 col5" >0.7768</td>
      <td id="T_e17a5_row9_col6" class="data row9 col6" >0.5692</td>
      <td id="T_e17a5_row9_col7" class="data row9 col7" >0.5707</td>
      <td id="T_e17a5_row9_col8" class="data row9 col8" >0.1340</td>
    </tr>
    <tr>
      <th id="T_e17a5_level0_row10" class="row_heading level0 row10" >lr</th>
      <td id="T_e17a5_row10_col0" class="data row10 col0" >Logistic Regression</td>
      <td id="T_e17a5_row10_col1" class="data row10 col1" >0.7802</td>
      <td id="T_e17a5_row10_col2" class="data row10 col2" >0.8665</td>
      <td id="T_e17a5_row10_col3" class="data row10 col3" >0.7383</td>
      <td id="T_e17a5_row10_col4" class="data row10 col4" >0.8060</td>
      <td id="T_e17a5_row10_col5" class="data row10 col5" >0.7706</td>
      <td id="T_e17a5_row10_col6" class="data row10 col6" >0.5604</td>
      <td id="T_e17a5_row10_col7" class="data row10 col7" >0.5624</td>
      <td id="T_e17a5_row10_col8" class="data row10 col8" >7.0660</td>
    </tr>
    <tr>
      <th id="T_e17a5_level0_row11" class="row_heading level0 row11" >nb</th>
      <td id="T_e17a5_row11_col0" class="data row11 col0" >Naive Bayes</td>
      <td id="T_e17a5_row11_col1" class="data row11 col1" >0.7685</td>
      <td id="T_e17a5_row11_col2" class="data row11 col2" >0.8110</td>
      <td id="T_e17a5_row11_col3" class="data row11 col3" >0.7697</td>
      <td id="T_e17a5_row11_col4" class="data row11 col4" >0.7678</td>
      <td id="T_e17a5_row11_col5" class="data row11 col5" >0.7687</td>
      <td id="T_e17a5_row11_col6" class="data row11 col6" >0.5369</td>
      <td id="T_e17a5_row11_col7" class="data row11 col7" >0.5370</td>
      <td id="T_e17a5_row11_col8" class="data row11 col8" >0.1080</td>
    </tr>
    <tr>
      <th id="T_e17a5_level0_row12" class="row_heading level0 row12" >svm</th>
      <td id="T_e17a5_row12_col0" class="data row12 col0" >SVM - Linear Kernel</td>
      <td id="T_e17a5_row12_col1" class="data row12 col1" >0.7531</td>
      <td id="T_e17a5_row12_col2" class="data row12 col2" >0.0000</td>
      <td id="T_e17a5_row12_col3" class="data row12 col3" >0.7241</td>
      <td id="T_e17a5_row12_col4" class="data row12 col4" >0.7728</td>
      <td id="T_e17a5_row12_col5" class="data row12 col5" >0.7436</td>
      <td id="T_e17a5_row12_col6" class="data row12 col6" >0.5061</td>
      <td id="T_e17a5_row12_col7" class="data row12 col7" >0.5118</td>
      <td id="T_e17a5_row12_col8" class="data row12 col8" >1.0380</td>
    </tr>
    <tr>
      <th id="T_e17a5_level0_row13" class="row_heading level0 row13" >dummy</th>
      <td id="T_e17a5_row13_col0" class="data row13 col0" >Dummy Classifier</td>
      <td id="T_e17a5_row13_col1" class="data row13 col1" >0.4998</td>
      <td id="T_e17a5_row13_col2" class="data row13 col2" >0.5000</td>
      <td id="T_e17a5_row13_col3" class="data row13 col3" >0.4000</td>
      <td id="T_e17a5_row13_col4" class="data row13 col4" >0.1999</td>
      <td id="T_e17a5_row13_col5" class="data row13 col5" >0.2666</td>
      <td id="T_e17a5_row13_col6" class="data row13 col6" >0.0000</td>
      <td id="T_e17a5_row13_col7" class="data row13 col7" >0.0000</td>
      <td id="T_e17a5_row13_col8" class="data row13 col8" >0.0900</td>
    </tr>
  </tbody>
</table>
</div><div class="output text_html"></div><div class="output text_html"></div><div class="output text_html"><style type="text/css">
#T_d0625_row10_col0, #T_d0625_row10_col1, #T_d0625_row10_col2, #T_d0625_row10_col3, #T_d0625_row10_col4, #T_d0625_row10_col5, #T_d0625_row10_col6 {
  background: yellow;
}
</style>
<table id="T_d0625">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_d0625_level0_col0" class="col_heading level0 col0" >Accuracy</th>
      <th id="T_d0625_level0_col1" class="col_heading level0 col1" >AUC</th>
      <th id="T_d0625_level0_col2" class="col_heading level0 col2" >Recall</th>
      <th id="T_d0625_level0_col3" class="col_heading level0 col3" >Prec.</th>
      <th id="T_d0625_level0_col4" class="col_heading level0 col4" >F1</th>
      <th id="T_d0625_level0_col5" class="col_heading level0 col5" >Kappa</th>
      <th id="T_d0625_level0_col6" class="col_heading level0 col6" >MCC</th>
    </tr>
    <tr>
      <th class="index_name level0" >Fold</th>
      <th class="blank col0" >&nbsp;</th>
      <th class="blank col1" >&nbsp;</th>
      <th class="blank col2" >&nbsp;</th>
      <th class="blank col3" >&nbsp;</th>
      <th class="blank col4" >&nbsp;</th>
      <th class="blank col5" >&nbsp;</th>
      <th class="blank col6" >&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_d0625_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_d0625_row0_col0" class="data row0 col0" >0.9926</td>
      <td id="T_d0625_row0_col1" class="data row0 col1" >1.0000</td>
      <td id="T_d0625_row0_col2" class="data row0 col2" >1.0000</td>
      <td id="T_d0625_row0_col3" class="data row0 col3" >0.9854</td>
      <td id="T_d0625_row0_col4" class="data row0 col4" >0.9927</td>
      <td id="T_d0625_row0_col5" class="data row0 col5" >0.9852</td>
      <td id="T_d0625_row0_col6" class="data row0 col6" >0.9853</td>
    </tr>
    <tr>
      <th id="T_d0625_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_d0625_row1_col0" class="data row1 col0" >0.9947</td>
      <td id="T_d0625_row1_col1" class="data row1 col1" >0.9998</td>
      <td id="T_d0625_row1_col2" class="data row1 col2" >0.9979</td>
      <td id="T_d0625_row1_col3" class="data row1 col3" >0.9916</td>
      <td id="T_d0625_row1_col4" class="data row1 col4" >0.9947</td>
      <td id="T_d0625_row1_col5" class="data row1 col5" >0.9895</td>
      <td id="T_d0625_row1_col6" class="data row1 col6" >0.9895</td>
    </tr>
    <tr>
      <th id="T_d0625_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_d0625_row2_col0" class="data row2 col0" >0.9884</td>
      <td id="T_d0625_row2_col1" class="data row2 col1" >0.9994</td>
      <td id="T_d0625_row2_col2" class="data row2 col2" >0.9937</td>
      <td id="T_d0625_row2_col3" class="data row2 col3" >0.9833</td>
      <td id="T_d0625_row2_col4" class="data row2 col4" >0.9885</td>
      <td id="T_d0625_row2_col5" class="data row2 col5" >0.9768</td>
      <td id="T_d0625_row2_col6" class="data row2 col6" >0.9768</td>
    </tr>
    <tr>
      <th id="T_d0625_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_d0625_row3_col0" class="data row3 col0" >0.9863</td>
      <td id="T_d0625_row3_col1" class="data row3 col1" >0.9998</td>
      <td id="T_d0625_row3_col2" class="data row3 col2" >0.9979</td>
      <td id="T_d0625_row3_col3" class="data row3 col3" >0.9753</td>
      <td id="T_d0625_row3_col4" class="data row3 col4" >0.9864</td>
      <td id="T_d0625_row3_col5" class="data row3 col5" >0.9726</td>
      <td id="T_d0625_row3_col6" class="data row3 col6" >0.9728</td>
    </tr>
    <tr>
      <th id="T_d0625_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_d0625_row4_col0" class="data row4 col0" >0.9916</td>
      <td id="T_d0625_row4_col1" class="data row4 col1" >1.0000</td>
      <td id="T_d0625_row4_col2" class="data row4 col2" >1.0000</td>
      <td id="T_d0625_row4_col3" class="data row4 col3" >0.9834</td>
      <td id="T_d0625_row4_col4" class="data row4 col4" >0.9916</td>
      <td id="T_d0625_row4_col5" class="data row4 col5" >0.9831</td>
      <td id="T_d0625_row4_col6" class="data row4 col6" >0.9833</td>
    </tr>
    <tr>
      <th id="T_d0625_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_d0625_row5_col0" class="data row5 col0" >0.9884</td>
      <td id="T_d0625_row5_col1" class="data row5 col1" >0.9997</td>
      <td id="T_d0625_row5_col2" class="data row5 col2" >0.9979</td>
      <td id="T_d0625_row5_col3" class="data row5 col3" >0.9793</td>
      <td id="T_d0625_row5_col4" class="data row5 col4" >0.9885</td>
      <td id="T_d0625_row5_col5" class="data row5 col5" >0.9768</td>
      <td id="T_d0625_row5_col6" class="data row5 col6" >0.9770</td>
    </tr>
    <tr>
      <th id="T_d0625_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_d0625_row6_col0" class="data row6 col0" >0.9937</td>
      <td id="T_d0625_row6_col1" class="data row6 col1" >1.0000</td>
      <td id="T_d0625_row6_col2" class="data row6 col2" >1.0000</td>
      <td id="T_d0625_row6_col3" class="data row6 col3" >0.9875</td>
      <td id="T_d0625_row6_col4" class="data row6 col4" >0.9937</td>
      <td id="T_d0625_row6_col5" class="data row6 col5" >0.9873</td>
      <td id="T_d0625_row6_col6" class="data row6 col6" >0.9874</td>
    </tr>
    <tr>
      <th id="T_d0625_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_d0625_row7_col0" class="data row7 col0" >0.9905</td>
      <td id="T_d0625_row7_col1" class="data row7 col1" >1.0000</td>
      <td id="T_d0625_row7_col2" class="data row7 col2" >1.0000</td>
      <td id="T_d0625_row7_col3" class="data row7 col3" >0.9813</td>
      <td id="T_d0625_row7_col4" class="data row7 col4" >0.9906</td>
      <td id="T_d0625_row7_col5" class="data row7 col5" >0.9810</td>
      <td id="T_d0625_row7_col6" class="data row7 col6" >0.9812</td>
    </tr>
    <tr>
      <th id="T_d0625_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_d0625_row8_col0" class="data row8 col0" >0.9905</td>
      <td id="T_d0625_row8_col1" class="data row8 col1" >0.9994</td>
      <td id="T_d0625_row8_col2" class="data row8 col2" >0.9979</td>
      <td id="T_d0625_row8_col3" class="data row8 col3" >0.9834</td>
      <td id="T_d0625_row8_col4" class="data row8 col4" >0.9906</td>
      <td id="T_d0625_row8_col5" class="data row8 col5" >0.9810</td>
      <td id="T_d0625_row8_col6" class="data row8 col6" >0.9811</td>
    </tr>
    <tr>
      <th id="T_d0625_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_d0625_row9_col0" class="data row9 col0" >0.9863</td>
      <td id="T_d0625_row9_col1" class="data row9 col1" >0.9998</td>
      <td id="T_d0625_row9_col2" class="data row9 col2" >0.9979</td>
      <td id="T_d0625_row9_col3" class="data row9 col3" >0.9753</td>
      <td id="T_d0625_row9_col4" class="data row9 col4" >0.9864</td>
      <td id="T_d0625_row9_col5" class="data row9 col5" >0.9725</td>
      <td id="T_d0625_row9_col6" class="data row9 col6" >0.9728</td>
    </tr>
    <tr>
      <th id="T_d0625_level0_row10" class="row_heading level0 row10" >Mean</th>
      <td id="T_d0625_row10_col0" class="data row10 col0" >0.9903</td>
      <td id="T_d0625_row10_col1" class="data row10 col1" >0.9998</td>
      <td id="T_d0625_row10_col2" class="data row10 col2" >0.9983</td>
      <td id="T_d0625_row10_col3" class="data row10 col3" >0.9826</td>
      <td id="T_d0625_row10_col4" class="data row10 col4" >0.9904</td>
      <td id="T_d0625_row10_col5" class="data row10 col5" >0.9806</td>
      <td id="T_d0625_row10_col6" class="data row10 col6" >0.9807</td>
    </tr>
    <tr>
      <th id="T_d0625_level0_row11" class="row_heading level0 row11" >Std</th>
      <td id="T_d0625_row11_col0" class="data row11 col0" >0.0028</td>
      <td id="T_d0625_row11_col1" class="data row11 col1" >0.0002</td>
      <td id="T_d0625_row11_col2" class="data row11 col2" >0.0018</td>
      <td id="T_d0625_row11_col3" class="data row11 col3" >0.0048</td>
      <td id="T_d0625_row11_col4" class="data row11 col4" >0.0027</td>
      <td id="T_d0625_row11_col5" class="data row11 col5" >0.0056</td>
      <td id="T_d0625_row11_col6" class="data row11 col6" >0.0055</td>
    </tr>
  </tbody>
</table>
</div><div class="output text_html"></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy with top 20 features: 99.1384%
Accuracy with top 19 features: 99.1384%
Accuracy with top 18 features: 99.2368%
Accuracy with top 17 features: 99.3107%
Accuracy with top 16 features: 99.2122%
Accuracy with top 15 features: 98.9414%
Accuracy with top 14 features: 98.9168%
Accuracy with top 13 features: 98.9660%
Accuracy with top 12 features: 99.0399%
Accuracy with top 11 features: 99.0645%
Accuracy with top 10 features: 99.0645%
Accuracy with top 9 features: 98.9414%
Accuracy with top 8 features: 98.9906%
Accuracy with top 7 features: 97.8090%
Accuracy with top 6 features: 97.6859%
Accuracy with top 5 features: 97.7843%
Accuracy with top 4 features: 97.5135%
Accuracy with top 3 features: 96.4057%
Accuracy with top 2 features: 86.6568%
Accuracy with top 1 features: 79.0497%

Best Accuracy: 99.31068439192516
Best k: 17
Best Selected Feature Names: Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;viruses&#39;, &#39;nitrates&#39;, &#39;nitrites&#39;, &#39;mercury&#39;,
       &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;, &#39;silver&#39;, &#39;uranium&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Random Forest&#39;</span><span class="p">,</span> <span class="s1">&#39;Logistic Regression&#39;</span><span class="p">,</span> <span class="s1">&#39;SVM&#39;</span><span class="p">,</span> <span class="s1">&#39;Naive Bayes&#39;</span><span class="p">,</span> <span class="s1">&#39;Adaboost&#39;</span><span class="p">,</span> <span class="s1">&#39;Gradient Boosting&#39;</span><span class="p">,</span> <span class="s1">&#39;Neural Network&#39;</span><span class="p">,</span> <span class="s1">&#39;Decision Tree&#39;</span><span class="p">,</span> <span class="s1">&#39;Pycaret Extra Tress Classifier&#39;</span><span class="p">]</span>

<span class="c1"># Daftar akurasi dari setiap metode</span>
<span class="n">accuracies</span> <span class="o">=</span> <span class="p">[</span><span class="n">accuracy_rf</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">accuracy_logreg</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">accuracy_svm</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">accuracy_nb</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">accuracy_adaboost</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">accuracy_gb</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">accuracy_nn</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">accuracy_dt</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">accuracy_pycr</span><span class="o">*</span><span class="mi">100</span><span class="p">]</span>

<span class="c1"># Membuat dataframe dari data</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Metode&#39;</span><span class="p">:</span> <span class="n">methods</span><span class="p">,</span> <span class="s1">&#39;Akurasi (%)&#39;</span><span class="p">:</span> <span class="n">accuracies</span><span class="p">}</span>
<span class="n">dataa</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Membuat grafik bar dengan Seaborn</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;Metode&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Akurasi (%)&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">dataa</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;pastel&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Metode&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Akurasi (%)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Perbandingan Akurasi antara Metode KNN&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="c1"># Menambahkan nilai-nilai akurasi di atas setiap batang</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">accuracies</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e1ef6528e9db520d7a4157e51f2da12ffca577111b9dbaf17d0162f4b5e5183a.png" src="../_images/e1ef6528e9db520d7a4157e51f2da12ffca577111b9dbaf17d0162f4b5e5183a.png" />
</div>
</div>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Proyek-Sains-Data_Mubessirul-Ummah_Water-Quality"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tujuan">Tujuan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#proses-pengolahan-data">Proses Pengolahan Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#center-data-understanding-center"><center><strong>——Data Understanding——</strong></center></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-data">1. Deskripsi Data</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-fitur-data">2. Deskripsi Fitur Data</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-tipe-data-fitur">3. Deskripsi Tipe Data Fitur</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#identifikasi-missing-value">4. Identifikasi Missing Value</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#identifikasi-duplikasi-data">5. Identifikasi Duplikasi Data</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#explorasi-data-menampilkan-grafik">6. Explorasi Data (Menampilkan Grafik)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#center-pre-processing-center"><center><strong>——Pre Processing——</strong></center></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#menemukan-data-outlier">1. Menemukan Data Outlier</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#balancing-class-data">2. Balancing Class Data</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#seleksi-fitur">3. Seleksi Fitur</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#normalisasi-dan-split-data">4. Normalisasi dan Split Data</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#center-pembuatan-model-center"><center><strong>Pembuatan Model</strong></center></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest">1. Random Forest</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">2. Logistic Regression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#svm">3. SVM</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes">4. Naive Bayes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adaboost">5. Adaboost</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting">6. Gradient Boosting</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-network">7. Neural Network</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#decission-tree">8. Decission Tree</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pycaret">9. Pycaret</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>